{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AUX Notebook.py",
      "provenance": [],
      "authorship_tag": "ABX9TyM3kPLLEnQTtvINN9KPsB/f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kasperbang/AEEEM/blob/main/AUX_Notebook_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is intended to show to computations behind the curtains. That is, here, one can expect to find functions that are used in our main notebook:\n",
        "https://colab.research.google.com/drive/1igEkqsbo0Zo9jfq1jWqeqvsavkoUEjRD#scrollTo=eQGC48qm1W2r "
      ],
      "metadata": {
        "id": "PpXqCP2St0dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Libraries and packages:\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "from scipy.io.arff import loadarff \n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "#Auxillary function to make our data readable:\n",
        "\n",
        "def numerical_response(df, data_set):\n",
        "    if data_set == 'AEEEM':\n",
        "        for i in range(len(df[\"class\"])):\n",
        "            if df[\"class\"].iloc[i][2:7] == 'clean':\n",
        "                df[\"class\"].iloc[i] = 0\n",
        "            else: \n",
        "                df[\"class\"].iloc[i] = 1\n",
        "\n",
        "        # df.loc[df[\"class\"] == b'buggy', \"class\"] = 1\n",
        "        # df.loc[df[\"class\"] == b'clean', \"class\"] = 0\n",
        "        \n",
        "    if data_set == 'NASA':\n",
        "        df.rename(columns={'Defective':'class'}, inplace=True)\n",
        "        df.loc[df[\"class\"] == 'Y', \"class\"] = 1\n",
        "        df.loc[df[\"class\"] == 'N', \"class\"] = 0\n",
        "        \n",
        "        \n",
        "    if data_set == 'PROMISE':\n",
        "        df.rename(columns={'bug':'class'}, inplace=True)\n",
        "        df.loc[df[\"class\"] > 0, \"class\"] = 1\n",
        "          \n",
        "    return "
      ],
      "metadata": {
        "id": "A6NyAcKeuGuK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Functions to help investigate data:\n",
        "\n",
        "def investigate_df(df):\n",
        "    data_points = len(df[\"class\"])\n",
        "    buggy = df[\"class\"].sum()\n",
        "    percent_buggy = round((buggy / data_points )* 100, 1) \n",
        "    print('Number of data points = ',data_points)\n",
        "    print('Number of buggy data points = ',buggy)\n",
        "    print('Percent buggy data points = ', percent_buggy, '%') \n",
        "    return \n",
        "\n",
        "\n",
        "\n",
        "def plot_two_columns(df, col_name1, col_name2):\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist2d(df[col_name1], df[col_name2], cmap=plt.cm.YlGn)\n",
        "    plt.colorbar()\n",
        "    plt.xlabel(col_name1)\n",
        "    \n",
        "    plt.subplot(1, 2,1)\n",
        "    plt.scatter(df[col_name1], df[col_name2])\n",
        "    plt.xlabel(col_name1)\n",
        "    plt.ylabel(col_name2)\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "\n",
        "\n",
        "def plot_var(df):\n",
        "    col_names = (df.columns).tolist()\n",
        "    for i in range(len(col_names)):\n",
        "        plot_two_columns(df, 'class', col_names[i])\n",
        "    return\n",
        "\n",
        "\n",
        "#Return a heatmap of pairwise correlation among all columns in a dataframe.\n",
        "def pearsoncor(df):\n",
        "  sns.heatmap(df.corr())\n",
        "  return\n",
        "\n",
        "\n",
        "#Create a histogram of all columns in a dataframe.\n",
        "def histofdf(df):  \n",
        "  df.hist(bins=20, \n",
        "          figsize=(25, 55),\n",
        "          xlabelsize = 12, \n",
        "          grid = False, \n",
        "          linewidth=3.0,\n",
        "          layout = (16,4))\n",
        "  return\n",
        "\n",
        "\n",
        "#Find columns in a project with correlation > X\n",
        "def find_correlated_columns(df, treshold):\n",
        "    correlated_columns = []\n",
        "    cor = df.corr()\n",
        "    np.fill_diagonal(cor.values, 0)\n",
        "    column_names = (cor.columns).to_list()\n",
        "    i = 0\n",
        "    current_length = len(column_names) - 1\n",
        "    while i < current_length:\n",
        "        max_value = max(abs(cor.iloc[i,:]))\n",
        "        if max_value > treshold:\n",
        "            correlated_columns.append(column_names[i])\n",
        "            cor.drop(columns=column_names[i], inplace=True)\n",
        "            current_length = current_length - 1\n",
        "\n",
        "        i = i + 1 \n",
        "    return correlated_columns\n",
        "\n",
        "\n",
        "\n",
        "#Drop specific features of a project to decrease dimensionality.\n",
        "def drop_variables(df, drop_list):\n",
        "    df.drop(columns=drop_list, inplace=True)\n",
        "    return\n"
      ],
      "metadata": {
        "id": "D2eFZ3EluG5P"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Functions to help tune the models:**"
      ],
      "metadata": {
        "id": "NyBAB4u8vU9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_feature_selection(df_train, df_test, func, scale = False):\n",
        "    # returns a drop list with variables we should drop\n",
        "    columns = df_train.columns.to_list()\n",
        "    number_of_columns = len(columns)\n",
        "    number_of_variables = len(columns) -1\n",
        "    auc_list = []\n",
        "    dropped_column_list = []\n",
        "\n",
        "    y_train = list(df_train['class'])\n",
        "    y_test = list(df_test['class'])\n",
        "    \n",
        "    if scale == True:\n",
        "        X_train, X_test = scale_data(df_train, df_test)\n",
        "        \n",
        "    if scale == False:\n",
        "        X_train = df_train.iloc[:,:-1]\n",
        "        X_test = df_test.iloc[:,:-1]\n",
        "    \n",
        "    X_train_copy = (X_train).copy()\n",
        "    X_test_copy = (X_test).copy()\n",
        "    \n",
        "    for j in range(number_of_columns - 2):\n",
        "        auc_temp_list = []\n",
        "        columns = X_train_copy.columns.to_list()\n",
        "        \n",
        "        number_of_columns = len(columns)\n",
        "        print(j,\" iteration done: \", number_of_columns - 2, \" iterations left.\")\n",
        "\n",
        "        for i in range(number_of_columns - 1):\n",
        "\n",
        "            X_train = X_train_copy.copy()\n",
        "            X_test = X_test_copy.copy()\n",
        "            X_train.drop(columns = columns[i], inplace=True)\n",
        "            X_test.drop(columns = columns[i], inplace=True)\n",
        "            \n",
        "            model = func()\n",
        "            model.fit(X_train, y_train)\n",
        "            \n",
        "            y_pred = model.predict(X_test)\n",
        "            auc_temp_list.append(roc_auc_score(y_test, y_pred))\n",
        "        \n",
        "        idx = np.argmax(auc_temp_list)\n",
        "        auc_list.append(auc_temp_list[idx])\n",
        "        dropped_column_list.append(columns[idx])\n",
        "        print(\"Removed \", columns[idx])\n",
        "        print(\"Shape of data frame: \",np.shape(X_train_copy),\"\\n\")\n",
        "        X_train_copy.drop(columns = columns[idx], inplace=True)\n",
        "        X_test_copy.drop(columns = columns[idx], inplace=True)\n",
        "    \n",
        "    idx_max_auc = np.argmax(auc_list)\n",
        "    print(\"\\nMax auc value: \",np.round(auc_list[idx_max_auc], 2))\n",
        "    print(\"and is found using \", number_of_variables-idx_max_auc ,\" variables.\")\n",
        "        \n",
        "    return dropped_column_list[0:idx_max_auc]\n",
        "\n",
        "\n",
        "\n",
        "def scale_data_unsupervised(df):\n",
        "    std_scaler = StandardScaler()\n",
        "    df_std = pd.DataFrame(std_scaler.fit_transform(df), columns=df.columns)\n",
        "    \n",
        "    return df_std\n",
        "\n",
        "\n",
        "\n",
        "def scale_data(train_data, test_data):\n",
        "    X_train = train_data.iloc[:,:-1]\n",
        "    X_test = test_data.iloc[:,:-1]\n",
        "    \n",
        "    std_scaler = StandardScaler()\n",
        "    \n",
        "    scaled_train_X = pd.DataFrame(std_scaler.fit_transform(X_train), columns=X_train.columns)\n",
        "    scaled_test_X = pd.DataFrame(std_scaler.fit_transform(X_test), columns=X_test.columns)\n",
        "\n",
        "    return scaled_train_X, scaled_test_X\n"
      ],
      "metadata": {
        "id": "hWB1_6_6uG8F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Performance of the models**"
      ],
      "metadata": {
        "id": "Pds4d5sxvi_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def AUC_unsupervised(function, df, project_list = 0):\n",
        "    y_pred, y_test = function(df)\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    \n",
        "    return np.round(np.mean(auc), 2)\n",
        "    \n",
        "    \n",
        "    \n",
        "def average_AUC_cross(function, df_test, projects = 0):\n",
        "    n = len(projects)\n",
        "    auc = np.zeros(n)\n",
        "    for j in range(n):\n",
        "        df_train = projects[j]\n",
        "        y_pred, y_test = function(df_train, df_test)\n",
        "        auc[j] = roc_auc_score(y_test, y_pred)\n",
        "        \n",
        "    return np.round(np.mean(auc), 2)\n",
        "\n",
        "\n",
        "\n",
        "def average_AUC_within(function, df, project_list = 0):\n",
        "    t = 500 # change to 500 for final results\n",
        "    auc = np.zeros(2*t)\n",
        "    for i in range(t):\n",
        "        df1, df2 = train_test_split(df, test_size=0.5)\n",
        "        y_pred, y_test = function(df1, df2)\n",
        "        auc[i] = roc_auc_score(y_test, y_pred)\n",
        "        y_pred, y_test = function(df2, df1)\n",
        "        auc[2*t - i - 1] = roc_auc_score(y_test, y_pred)\n",
        "    return np.round(np.mean(auc), 2)\n",
        "\n",
        "\n",
        "\n",
        "def get_auc_scores(project_dict, func, auc_func):\n",
        "    average_auc_list = []\n",
        "    \n",
        "    project_list = list(project_dict.values())\n",
        "    project_names = list(project_dict.keys())\n",
        "    \n",
        "    all_projects = project_list\n",
        "\n",
        "    for p in range(len(project_list)): \n",
        "        # only for cross project        \n",
        "        train_project = all_projects.copy()\n",
        "        train_project.pop(p)\n",
        "        \n",
        "        # for all (cross project, within project and unsupervised)\n",
        "        test_project = project_list[p]\n",
        "\n",
        "        auc = auc_func(func, test_project, train_project)\n",
        "        print('\\nAUC score for ' + project_names[p] + ' :', auc)\n",
        "        average_auc_list.append(auc)\n",
        "    \n",
        "    print('\\nMean AUC score for all projects:', np.round(np.mean(average_auc_list),2))  \n",
        "    return average_auc_list\n",
        "\n",
        "\n",
        "\n",
        "def scott_knott(function, df):\n",
        "    t = 500 # change to 500 for final results\n",
        "    auc = np.zeros(2*t)\n",
        "    for i in range(t):\n",
        "        df1, df2 = train_test_split(df, test_size=0.5)\n",
        "        y_pred, y_test = function(df1, df2)\n",
        "        auc[i] = roc_auc_score(y_test, y_pred)\n",
        "        y_pred, y_test = function(df2, df1)\n",
        "        auc[2*t - i - 1] = roc_auc_score(y_test, y_pred)\n",
        "    print(len(auc))\n",
        "    \n",
        "    return auc\n",
        "\n"
      ],
      "metadata": {
        "id": "DhX8iK7TvpcO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **To present results:**"
      ],
      "metadata": {
        "id": "M8NZ0crHvdtz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "56jTUwA4tsR7"
      },
      "outputs": [],
      "source": [
        "def to_csv_supervised(project_dict, function_dict, file_name):\n",
        "    measure = ['CP', 'WP', 'diff']\n",
        "    m = len(measure)\n",
        "    function_names = list(function_dict.keys())\n",
        "    column_names =[]\n",
        "    for i in range(len(function_dict)):\n",
        "        for j in range(m):\n",
        "            column_names.append(function_names[i] + '\\n' + measure[j])\n",
        "    project_list = list(project_dict.values())\n",
        "    function_list = list(function_dict.values())\n",
        "    row_names = list(project_dict.keys())\n",
        "    \n",
        "    col = 0\n",
        "    all_projects = project_list\n",
        "    \n",
        "    # initialize data\n",
        "    data = np.zeros((len(project_list), len(function_list)*m))\n",
        "    for func in function_list:\n",
        "        print(func) # del\n",
        "        for p in range(len(project_list)):         \n",
        "            train_project = all_projects.copy()\n",
        "            train_project.pop(p)\n",
        "            \n",
        "            test_project = project_list[p]\n",
        "            \n",
        "            AUC_cross = average_AUC_cross(func, test_project, train_project)\n",
        "            AUC_within = average_AUC_within(func, test_project)\n",
        "            \n",
        "            data[p,col] = AUC_cross\n",
        "            data[p,col+1] = AUC_within\n",
        "            data[p,col+2] = round(AUC_within - AUC_cross,2)\n",
        "            print(project_list[p])           \n",
        "        col = col + m\n",
        "    df = pd.DataFrame(data, index = row_names) \n",
        "    df.to_csv(file_name, encoding='utf-8', index=True, header=column_names)\n",
        "    return\n",
        "\n",
        "\n",
        "\n",
        "def to_csv_unsupervised(project_dict, function_dict, file_name):\n",
        "    function_names = list(function_dict.keys())\n",
        "    column_names =[]\n",
        "    for i in range(len(function_dict)):\n",
        "        column_names.append(function_names[i])\n",
        "    \n",
        "    project_list = list(project_dict.values())\n",
        "    function_list = list(function_dict.values())\n",
        "    row_names = list(project_dict.keys())\n",
        "    \n",
        "    col = 0\n",
        "    all_projects = project_list\n",
        "    \n",
        "    # initialize data\n",
        "    data = np.zeros((len(project_list), len(function_list)))\n",
        "    for func in function_list:\n",
        "        for p in range(len(project_list)):         \n",
        "            df = project_list[p]\n",
        "    \n",
        "            AUC = AUC_unsupervised(func, df)\n",
        "            data[p,col] = AUC\n",
        "            \n",
        "    df = pd.DataFrame(data, index = row_names) \n",
        "    df.to_csv(file_name, encoding='utf-8', index=True, header=column_names)\n",
        "    return\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}