{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kasperbang/AEEEM/blob/main/prosjekt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTEBOOKS**:\n",
        "\n",
        "AUX NOTEBOOK LINK:\n",
        "\n",
        "https://colab.research.google.com/drive/1hzOTMxUuArJ9aEHd3ZeUUw8YHY1pUEP7?usp=sharing\n",
        "\n",
        "AEEEM:\n",
        "\n",
        "https://colab.research.google.com/drive/1EUIvKVZ1T00ysia1UZwoiDXjDCfJ07K-?usp=sharing\n",
        "\n",
        "NASA:\n",
        "\n",
        "https://colab.research.google.com/drive/1Twj7l6iBBVZYqjupfwworA0vvFyXt1_J?usp=sharing\n",
        "\n",
        "\n",
        "PROMISE:\n",
        "\n",
        "https://colab.research.google.com/drive/1TE3GoPllsuSpkg4Sdu6vP3JEtDMqVyWN?usp=sharing\n"
      ],
      "metadata": {
        "id": "CW0Gk2VJwL4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Run AUX Notebook:\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "mt9j1JSrylOG",
        "outputId": "04aac8d8-ea72-4eaa-fee1-e67316a51316"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8be6afd6fc72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Run AUX Notebook:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m       \u001b[0muse_metadata_server\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_metadata_server\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m       ephemeral=ephemeral)\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server, ephemeral)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 136\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzwpQI51kb1h"
      },
      "source": [
        "# To do\n",
        "\n",
        "* Random forrest! We need to finetune the parameters and potentially punish false negatives more.\n",
        "* Spectral clustering algorithm (almost there I think)\n",
        "\n",
        "* Logistic regression: We are not getting good results for everything except AEEEM within, but this one is still 0.1 off what they are getting. All other results are very bad.\n",
        "\n",
        "* \n",
        "\n",
        "* Feature selection. AEEEM is most important.\n",
        "  \n",
        "* Theory / descrition of Spectral clustering\n",
        "\n",
        "*   Implement the Scott Knott- test\n",
        "*   Discussion\n",
        "*   Reasearch Q\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN8wxDoxav7T"
      },
      "source": [
        "# Title\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCCLfdUxbGU8"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "The objective of this project is to reproduce the study by Zhang, Zheng, Zou, and Hassan in 2016: \"Cross-project Defect Prediction Using a Connectivity-based Unsupervised Classifier\". The paper aims to predict software defects using known data from 18 different projects extracted from three different datasets. The authors first apply known machine-learning algorithms such as k-means, naive bayes, logistic regression, and random forest to test if any of these can delivery satisfactory performances. However, they all seem to have their respective problems. \n",
        "\n",
        "In software defect prediction, there is typically only a very limited amount of training data. This is a natural consequence to the heterogeneity that exists among software. As a result, superviced classifiers are not being fed an adequate amount of training data. K-means is a known and widely used algorithm for unsupervised learning, but it performs poorly in this setting. One of the main reasons, according to Zhang et al, is that the data is not linearly seperable (other reasons are explained in the section on k-means clustering). \n",
        "\n",
        "The underperformance or general impracticability of these algorithms thus leaves a vacuum. Spectral Clustering rises to fill this vacuum and are superior due to e.g. less rigid assumptions on linear seperability and the fact that it is unsupervised and thus do not need training data from homogene projects.\n",
        "\n",
        "\n",
        "The authors do largely not themselves perform any feature selection which is one of the optimizations we will do. More specifically, we will try to impose a higher cost to our algorithms for false negatives than for false positives. In the time of a global pandemic, we are reminded that misclassifiying a positive, as a negative, can be much worse than misclassifying a negative as a positive. As a result, we want to impose a higher cost to our models for making false-negatives. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQnff38-dW61"
      },
      "source": [
        "# Research Questions\n",
        "\n",
        "## Q1: How does spactral clustering performs compared to the supervised learning methods. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymrxJMqugH2b"
      },
      "source": [
        "# Auxiliary functions and set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lr4oBFue0nZs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import seaborn as sns\n",
        "from scipy.io.arff import loadarff \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmNvSFl8cJMd"
      },
      "outputs": [],
      "source": [
        "def investigate_df(df):\n",
        "    data_points = len(df[\"class\"])\n",
        "    buggy = df[\"class\"].sum()\n",
        "    percent_buggy = round((buggy / data_points )* 100, 1) \n",
        "    print('Number of data points = ',data_points)\n",
        "    print('Number of buggy data points = ',buggy)\n",
        "    print('Percent buggy data points = ', percent_buggy)\n",
        "    return \n",
        "\n",
        "    \n",
        "def find_correlated_columns(df, treshold):\n",
        "    correlated_columns = []\n",
        "    cor = df.corr()\n",
        "    np.fill_diagonal(cor.values, 0)\n",
        "    column_names = (cor.columns).to_list()\n",
        "    i = 0\n",
        "    current_length = len(column_names) - 1\n",
        "    while i < current_length:\n",
        "        max_value = max(abs(cor.iloc[i,:]))\n",
        "        if max_value > treshold:\n",
        "            correlated_columns.append(column_names[i])\n",
        "            cor.drop(columns=column_names[i], inplace=True)\n",
        "            current_length = current_length - 1\n",
        "\n",
        "        i = i + 1 \n",
        "    return correlated_columns\n",
        "\n",
        "\n",
        "def drop_variables(df, drop_list):\n",
        "    df.drop(columns=drop_list, inplace=True)\n",
        "    return\n",
        "\n",
        "def scale_data_unsupervised(df):\n",
        "    std_scaler = StandardScaler()\n",
        "    df_std = pd.DataFrame(std_scaler.fit_transform(df), columns=df.columns)\n",
        "    \n",
        "    return df_std\n",
        "\n",
        "def scale_data(train_data, test_data):\n",
        "    X_train = train_data.iloc[:,:-1]\n",
        "    X_test = test_data.iloc[:,:-1]\n",
        "    \n",
        "    std_scaler = StandardScaler()\n",
        "    \n",
        "    scaled_train_X = pd.DataFrame(std_scaler.fit_transform(X_train), columns=X_train.columns)\n",
        "    scaled_test_X = pd.DataFrame(std_scaler.fit_transform(X_test), columns=X_test.columns)\n",
        "\n",
        "    return scaled_train_X, scaled_test_X\n",
        "\n",
        "\n",
        "def numerical_response(df, data_set):\n",
        "    if data_set == 'AEEEM':\n",
        "        \n",
        "        for i in range(len(df[\"class\"])):\n",
        "            if df[\"class\"][i][2:7] == 'clean':\n",
        "                df[\"class\"][i] = 0\n",
        "            else: \n",
        "                df[\"class\"][i] = 1\n",
        "\n",
        "        # df.loc[df[\"class\"] == b'buggy', \"class\"] = 1\n",
        "        # df.loc[df[\"class\"] == b'clean', \"class\"] = 0\n",
        "\n",
        "        \n",
        "        \n",
        "    if data_set == 'NASA':\n",
        "        df.rename(columns={'Defective':'class'}, inplace=True)\n",
        "        df.loc[df[\"class\"] == 'Y', \"class\"] = 1\n",
        "        df.loc[df[\"class\"] == 'N', \"class\"] = 0\n",
        "        \n",
        "        \n",
        "    if data_set == 'PROMISE':\n",
        "        df.rename(columns={'bug':'class'}, inplace=True)\n",
        "        df.loc[df[\"class\"] > 0, \"class\"] = 1\n",
        "          \n",
        "    return \n",
        "\n",
        "\n",
        "\n",
        "def AUC_unsupervised(function, df, project_list = 0):\n",
        "    y_pred, y_test = function(df)\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    \n",
        "    return np.round(np.mean(auc), 2)\n",
        "    \n",
        "    \n",
        "def average_AUC_cross(function, df_test, projects = 0):\n",
        "    n = len(projects)\n",
        "    auc = np.zeros(n)\n",
        "    for j in range(n):\n",
        "        df_train = projects[j]\n",
        "        y_pred, y_test = function(df_train, df_test)\n",
        "        auc[j] = roc_auc_score(y_test, y_pred)\n",
        "        \n",
        "    return  np.round(np.mean(auc), 2)\n",
        "\n",
        "\n",
        "def average_AUC_within(function, df, project_list = 0):\n",
        "    t = 500 # change to 500 for final results\n",
        "    auc = np.zeros(2*t)\n",
        "    for i in range(t):\n",
        "        df1, df2 = train_test_split(df, test_size=0.5)\n",
        "        y_pred, y_test = function(df1, df2)\n",
        "        auc[i] = roc_auc_score(y_test, y_pred)\n",
        "        y_pred, y_test = function(df2, df1)\n",
        "        auc[2*t - i - 1] = roc_auc_score(y_test, y_pred)\n",
        "        \n",
        "    return np.round(np.mean(auc), 2)\n",
        "\n",
        "\n",
        "\n",
        "def get_auc_scores(project_dict, func, auc_func):\n",
        "    average_auc_list = []\n",
        "    \n",
        "    \n",
        "    project_list = list(project_dict.values())\n",
        "    project_names = list(project_dict.keys())\n",
        "    \n",
        "    all_projects = project_list\n",
        "\n",
        "    for p in range(len(project_list)): \n",
        "        # only for cross project        \n",
        "        train_project = all_projects.copy()\n",
        "        train_project.pop(p)\n",
        "        \n",
        "        # for all (cross project, within project and unsupervised)\n",
        "        test_project = project_list[p]\n",
        "\n",
        "        auc = auc_func(func, test_project, train_project)\n",
        "        print('\\nAUC score for ' + project_names[p] + ' :', auc)\n",
        "        average_auc_list.append(auc)\n",
        "    \n",
        "    print('\\nMean AUC score for all projects:', np.round(np.mean(average_auc_list),2))  \n",
        "    return \n",
        "\n",
        "\n",
        "def to_csv_supervised(project_dict, function_dict, file_name):\n",
        "    measure = ['CP', 'WP', 'diff']\n",
        "    m = len(measure)\n",
        "    function_names = list(function_dict.keys())\n",
        "    column_names =[]\n",
        "    for i in range(len(function_dict)):\n",
        "        for j in range(m):\n",
        "            column_names.append(function_names[i] + '\\n' + measure[j])\n",
        "    project_list = list(project_dict.values())\n",
        "    function_list = list(function_dict.values())\n",
        "    row_names = list(project_dict.keys())\n",
        "    \n",
        "    col = 0\n",
        "    all_projects = project_list\n",
        "    \n",
        "    # initialize data\n",
        "    data = np.zeros((len(project_list), len(function_list)*m))\n",
        "    for func in function_list:\n",
        "        print(func) # del\n",
        "        for p in range(len(project_list)):         \n",
        "            train_project = all_projects.copy()\n",
        "            train_project.pop(p)\n",
        "            \n",
        "            test_project = project_list[p]\n",
        "            \n",
        "            AUC_cross = average_AUC_cross(func, test_project, train_project)\n",
        "            AUC_within = average_AUC_within(func, test_project)\n",
        "            \n",
        "            data[p,col] = AUC_cross\n",
        "            data[p,col+1] = AUC_within\n",
        "            data[p,col+2] = round(AUC_within - AUC_cross,2)\n",
        "            print(project_list[p])\n",
        "            \n",
        "        col = col + m\n",
        "    df = pd.DataFrame(data, index = row_names) \n",
        "    df.to_csv(file_name, encoding='utf-8', index=True, header=column_names)\n",
        "    \n",
        "    return\n",
        "\n",
        "\n",
        "def to_csv_unsupervised(project_dict, function_dict, file_name):\n",
        "    function_names = list(function_dict.keys())\n",
        "    column_names =[]\n",
        "    for i in range(len(function_dict)):\n",
        "        column_names.append(function_names[i])\n",
        "    \n",
        "    project_list = list(project_dict.values())\n",
        "    function_list = list(function_dict.values())\n",
        "    row_names = list(project_dict.keys())\n",
        "    \n",
        "    col = 0\n",
        "    all_projects = project_list\n",
        "    \n",
        "    # initialize data\n",
        "    data = np.zeros((len(project_list), len(function_list)))\n",
        "    for func in function_list:\n",
        "        for p in range(len(project_list)):         \n",
        "            df = project_list[p]\n",
        "    \n",
        "            AUC = AUC_unsupervised(func, df)\n",
        "            data[p,col] = AUC\n",
        "            \n",
        "    df = pd.DataFrame(data, index = row_names) \n",
        "    df.to_csv(file_name, encoding='utf-8', index=True, header=column_names)\n",
        "    \n",
        "    return\n",
        "\n",
        "#Using Pearson Correlation\n",
        "def pearsoncor(df):\n",
        "  df.corr()\n",
        "  sns.heatmap(df.corr())\n",
        "  return\n",
        "\n",
        "def histofdf(df):  \n",
        "  df.hist(bins=20, \n",
        "          figsize=(25, 55),\n",
        "          xlabelsize = 12, \n",
        "          grid = False, \n",
        "          linewidth=3.0,\n",
        "          layout = (16,4))\n",
        "  return\n",
        "\n",
        "def plot_two_columns(df, col_name1, col_name2):\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist2d(df[col_name1], df[col_name2], cmap=plt.cm.YlGn)\n",
        "    plt.colorbar()\n",
        "    plt.xlabel(col_name1)\n",
        "    plt.ylabel(col_name2)\n",
        "    \n",
        "    plt.subplot(1, 2,1)\n",
        "    plt.scatter(df[col_name1], df[col_name2])\n",
        "    plt.xlabel(col_name1)\n",
        "    plt.ylabel(col_name2)\n",
        "    plt.show()\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldMmAj0va0IH"
      },
      "source": [
        "# Explanation (and exploration) of the data sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UWundSra_hh"
      },
      "source": [
        "### AEEEM\n",
        "\n",
        "\n",
        "#See APPENDIX 1 for explanation of all variables. Only the most important will be discussed in the project directly.\n",
        "\n",
        "\n",
        "#### Show them examples from the data\n",
        "correlation between our two favourite metrics?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WV8PcB_AxB5i"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import io\n",
        "\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Kasperbang/AEEEM/main/AEEEM_EQ.csv\" \n",
        "download = requests.get(url).content\n",
        "AEEEM_EQ = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Kasperbang/AEEEM/main/AEEEM_JDT.csv\" \n",
        "download = requests.get(url).content\n",
        "AEEEM_JDT = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Kasperbang/AEEEM/main/AEEEM_LC.csv\" \n",
        "download = requests.get(url).content\n",
        "AEEEM_LC = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Kasperbang/AEEEM/main/AEEEM_ML.csv\" \n",
        "download = requests.get(url).content\n",
        "AEEEM_ML = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Kasperbang/AEEEM/main/AEEEM_PDE.csv\" \n",
        "download = requests.get(url).content\n",
        "AEEEM_PDE = pd.read_csv(io.StringIO(download.decode('utf-8')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xbs0uJgICGsP",
        "outputId": "ee820890-09a7-4983-f361-93ec4ae70df8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ],
      "source": [
        "numerical_response(AEEEM_JDT, 'AEEEM')\n",
        "numerical_response(AEEEM_EQ, 'AEEEM')\n",
        "numerical_response(AEEEM_LC, 'AEEEM')\n",
        "numerical_response(AEEEM_ML, 'AEEEM')\n",
        "numerical_response(AEEEM_PDE, 'AEEEM') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmqIgX8ZgfEN"
      },
      "source": [
        "### Feature Selection - AEEEM DATASET\n",
        "As seen above, this dataset has 61 predictor variables which prove impractical for multiple reasons. \n",
        "\n",
        "1)\n",
        "Firstly, it is overwhelming to actually understand what the variables are telling us and human intuition is therefore benched. We do not want that as it eliminates our chance to sanity check. Decreasing dimensionality would therefore increase interpretability. \n",
        "\n",
        "2)\n",
        "Secondly, and more theoretically founded, the enormous amount of predictors can lead to the curse of dimensionality. The curse of dimensionality, in its essence, is about the fact that as dimensions increase, clusters become more dissimilar. \n",
        "\n",
        "An intuitive example could be to investigate 100 people and only ask them about their weight to predict their sex. This would create two distinct clusters: Men and Women. However, imagine doing the same in multi-dimensional space. Asking about hair color, eye color, length of toes, height, weight, number of scars, etc. This would clearly increase the dissimilarity within the clusters and therefore make it less certain how to predict a marginal person's gender.\n",
        "\n",
        "3)\n",
        "Thirdly, having many dimensions to optimize over increases computation time. \n",
        "\n",
        "4)\n",
        "Lastly, it follows from the imbalanced nature of our data-set that machine learning models works poorly with default parameters. The logic may be understood more clearly with another intuitive example. Imaginge that only 1% of observations are defect, that would mean that the algorithm can obtain a 99% accuracy by simply classifying everything as not-defect. \n",
        "As a result, it is important to decide if the model should be trained to improve Sensitivity (\"Number of predicted defects\"/\"Total number of defects\"), Specificity (\"Number of predicted negatives\" / \"Total negatives\"), or the AUC score which is the relationship between the two.\n",
        "\n",
        "\n",
        "As a result, we will now proceed to decrease the number of features. We will discover how we do so for this dataset. \n",
        "\n",
        "***SIMILAR THOUGHTS GOES INTO THE SAME DIMENSIONALITY REDUCTION FOR THE OTHER DATASETS***\n",
        "\n",
        "\n",
        "\n",
        "Now we will proceed by selection our features. We follow these rules:\n",
        "\n",
        "1) Intuition. Features that are not explained in Appendix 1 will be discarded. \n",
        "\n",
        "2) Apply variance threshold method. The notion is that 0-variance variables have no predictive power. Since our dataset is imbalanced  (see Table 1), we will be less strict than suggested on the official sklearn documentation to \"VarianceThreshold\". We apply this method because we, through manual examination, realized that multiple features provide very little variance and thus only adds complexity and noise. \n",
        "\n",
        "3) Recursive feature selection which recusively goes through our model and removes the least important features. Forward feature selection. Best model selection. \n",
        "\n",
        "4) We can apply over/under-sampling.\n",
        "  Over sampling is the exercise of increasing the number of the minority class to increase the balance of the data set. That is, to add randomly selected rows with defects. Under-sampling is the exact opposite. To remove a number of randomly selected rows with not-defects to increase sampling.\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvWJzzcKCEEg"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "1) Intuition. Here we are removing features that are either not explained or \n",
        "have any intuitive implication to our outcome variable.\n",
        "This will help us improve interpretability.\n",
        "'''\n",
        "\n",
        "drop_list = [\"Unnamed: 0\"]\n",
        "correlated = find_correlated_columns(AEEEM_ML, 0.76) # 0.75!\n",
        "\n",
        "drop_list = drop_list + correlated\n",
        "\n",
        "#pearsoncor(AEEEM_PDE.loc[:, drop_list])\n",
        "\n",
        "drop_variables(AEEEM_JDT, drop_list)\n",
        "drop_variables(AEEEM_EQ, drop_list)\n",
        "drop_variables(AEEEM_LC, drop_list)\n",
        "drop_variables(AEEEM_ML, drop_list)\n",
        "drop_variables(AEEEM_PDE, drop_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3flaFY5gawk"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Not used for now\n",
        "\n",
        "'''\n",
        "2) Variance Threshold method:\n",
        "\n",
        "\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "#df = AEEEM_EQ.copy()\n",
        "\n",
        "VarThreshold = 0.00\n",
        "\n",
        "def vart(df, thold):\n",
        "  length = len(df.columns)\n",
        "  X = df.iloc[:,:length-1]\n",
        "  selector = VarianceThreshold(threshold=thold)\n",
        "  selector.fit(X)\n",
        "  \n",
        "  return X[X.columns[selector.get_support(indices=True)]]\n",
        "\n",
        "AEEEM_EQ = vart(AEEEM_EQ, VarThreshold)\n",
        "AEEEM_ML = vart(AEEEM_ML, VarThreshold)\n",
        "AEEEM_JDT = vart(AEEEM_JDT, VarThreshold)\n",
        "AEEEM_PDE = vart(AEEEM_PDE, VarThreshold)\n",
        "AEEEM_LC = vart(AEEEM_LC, VarThreshold)\n",
        "\n",
        "\n",
        "print(len(AEEEM_EQ.columns))\n",
        "print(len(AEEEM_ML.columns))\n",
        "print(len(AEEEM_JDT.columns))\n",
        "print(len(AEEEM_PDE.columns))\n",
        "print(len(AEEEM_LC.columns))\n",
        "´´´"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hz5MSBte9afv"
      },
      "outputs": [],
      "source": [
        "#Not used currently.\n",
        "corr_matrix = AEEEM_JDT.corr()\n",
        "print(corr_matrix.loc[\"class\"].sort_values(ascending=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5pZWzhM24Wa"
      },
      "outputs": [],
      "source": [
        "project_dict_AEEEM = {\n",
        "  \"Eclipse JDT Core, AEEEM_JDT  \": AEEEM_JDT,\n",
        "  \"Equinox, AEEEM_EQ \": AEEEM_EQ,\n",
        "  \"Apache Lucene , AEEEM_LC \": AEEEM_LC,\n",
        "  \"Mylyn, AEEEM_ML\" : AEEEM_ML,\n",
        "  \"Eclipse PDE UI, AEEEM_PDE \": AEEEM_PDE}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwaUetl63pGZ",
        "outputId": "9e560219-bb3b-4017-8658-33fb1c4aa573"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "36\n"
          ]
        }
      ],
      "source": [
        "##Histogram visualization\n",
        "'''\n",
        "Below is presented the histograms to illustrate the distribution of the data.\n",
        "Our example is the largest project in our dataset.\n",
        "'''\n",
        "##Asses the distribution of values in a representative AEEEM Project:\n",
        "histofdf(AEEEM_PDE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hueH55mdJjeb"
      },
      "outputs": [],
      "source": [
        "#Not used right now\n",
        "'''This should be a table that shows us if we have outliers in the data!'''\n",
        "\n",
        "def outliertable(df):    \n",
        "    Q1 = df.quantile(0.25)\n",
        "    Q3 = df.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    print(IQR)\n",
        "    print(df < (Q1 - 1.5 * IQR)) and (df > (Q3 + 1.5 * IQR))\n",
        "\n",
        "outliertable(AEEEM_EQ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JO2be3kbfxHa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "5b0c0c72-ac0e-48d1-e4ee-d0c3a863b33b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAEKCAYAAADJvIhZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfbxcVX3v8c/3nAQ4+MCBJHJJQk0oMV6QaiByufZJpZpoleQqaKhVtNTUCq2tbappKyiVqo1XqtXqTYUCXgUxYIy32IiAcu01gRODhIDRGEByAEkIoSon5IHf/WPvCXMm83xmz8ye+b557Vdmr71nz5phz/nNWnvt31JEYGZm1g4Dna6AmZn1DwcdMzNrGwcdMzNrGwcdMzNrGwcdMzNrGwcdMzNrGwcdMzM7SNIVkh6VdHdR2UskrZN0p6QRSaen5ZL0KUlbJd0l6dRax3fQMTOzYlcCC0vK/gH4UES8BLgoXQd4DTAnXZYCn611cAcdMzM7KCJuA3aVFgPPTR8fBTyUPl4EXB2JdcCwpOOqHX9SKyvbzaZOnRqzZs3qdDWsR23YsGFnRExr9+tOnXpMzJp1fLtf1tpsw4a7qp5fmvrsYO+B2gf6+Z7NwJ6ikpURsbKOKvwZsFbSx0kaKy9Ly2cADxbttz0te7jSgfom6MyaNYuRkZFOV8N6lKQHOvG6s2Ydz8jINzrx0ta0xlOPSTOrn197D8AZs2sf6KZ790TE/IYrAH8M/HlEXC/pTcDlwO80cRx3r5mZ5Z7qXJp3HnBD+vgrwOnp41GguKk9My2ryEHHzKwXDKj20ryHgN9OH78S+HH6eA3wtnQU2xnAExFRsWsN+qh7zcysp2liTZlnDqNrgJcDUyVtBy4G3gl8UtIkkmtCS9PdbwReC2wFngTeUev4DjpmZr2gNTGHiDi3wqbTyuwbwAWNHN9Bx8ws78REu8/axkHHrIbVG0dZsXYLD+0eY/rwEMsWzGXxvBmdrpbZePmIOQ46ZtWs3jjK8hs2MbYvuQdidPcYy2/YBODAY11ELbumkzWPXjOrYsXaLQcDTsHYvgOsWLulQzUyK0Mkf81rLV3ALR2zKh7aPdZQuVnHuKVjln/Th4caKjfrmGxvDm0ZBx2zKpYtmMvQ5MFxZUOTB1m2YG6HamRWgVR76QLuXjOrojBYwKPXrKt1UUumFgcdsxoWz5vhIGPdbzAfUcdBx8ysF+Qj5jjomJnlnuiaaza1OOiYmfWCfMQcBx0zs/zrntFptTjomJn1gnzEHAcdM7Pcy1GWad8cambWC1p0c6ikKyQ9KunukvI/kfRDSZsl/UNR+XJJWyVtkbSg1vHd0jEz6wWta+hcCXwauPrgoaVXAIuAF0fEU5Kel5afBCwBTgamA9+S9IKIOHDIUVNu6ZiZtVU9SdKaSJrWoizTEXEbsKuk+I+Bj0bEU+k+j6bli4BrI+KpiLiPZNrq02tV08zM8qxwn052uddeAPympPWSviPppWn5DODBov22p2UVuXvNzKwX1DeQYKqkkaL1lRGxso7nTQKOAc4AXgpcJ+mExivpoGNm1hvqa8jsjIj5TRx9O3BDRARwu6SnganAKHB80X4z07KK3L1mZpZ7dXStTax7bTXwCgBJLwAOA3YCa4Alkg6XNBuYA9xe7UBu6ZiZ5V0LpzaQdA3wcpKuuO3AxcAVwBXpMOq9wHlpq2ezpOuAe4D9wAXVRq6Bg45ZJiQdTjLk9DTgMeDNEXG/pFcBHyX5pbgXWBYRt6TPOY1kuOoQcCPwnvSLbVZTPQ2Zek6miDi3wqbfr7D/pcCldRwacPeaWascUbJ+PvB4RJwIXAZ8LC3fCbw+Ik4BzgO+UPSczwLvJOmimAMszLTG1lMk1Vy6gYOOWWsMl6wvAq5KH68CzpSkiNgYEQ+l5ZuBobQ//DjguRGxLm3dXA0sbkvNLfcEDA6o5tINHHTMWuOwkvWD9y9ExH7gCWBKyT5vBL6f3nA3g2SEUEHF+x0kLZU0Imlkx47HWlF3y7vMxxG0joOOWQdIOpmky+2PGn1uRKyMiPkRMX/atNI4Zv2qRXkNMuegY9Yae0vWD96/IGkScBTJgAIkzQS+CrwtIn5StP/MoufXvN/BrJiv6Zj1l90l62tIBgoAnA3cEhEhaRj4N+D9EfEfhZ0j4mHgPyWdoeSvw9uAr7Wh3tYj3L2WkrQwTXm9VdL7y2w/XNKX0+3rJc1Ky18laYOkTem/ryx6zmlp+VZJn1K3hHDrZ3skXSLprHT9cmCKpK3Ae4HCuX8hcCJwkaQ70+V56bZ3A58nSZr4E+Ab7au+5Vn2qddaJ9P7dCQNAp8BXkVyYfQOSWsi4p6i3Q4OLZW0hKSf+808M7T0IUkvAtbyzIXVwtDS9ST3MyzEX1DrsIi4qOjxHuCcMvt8GPhwheePAC/KrILWuwQDXTI6rZasWzqnA1sjYltE7AWuJRlKWsxDS83MJqT29Zxu6RDKOujUk/a6TUNLdzT9JszMul1eute6fiBB64aWTmt95czMuoBo2Rxumcu6HvWkvfbQUjOzCXL3WuIOYI6k2ZIOI5lLe03JPh5aamY2EYKBgdpLN8i0Guk1mgtJRp7dC1wXEZs9tNTMrHWSIdP5aOlkPrVBRNxIMqy5uMxDS82sLwVVp5tpWpfElJo8n46ZWQ/olpZMLV3Sy2dmZhPRqiHTkq6Q9Gg6S2jptr+QFJKmputKs8JslXSXpFNrHd9Bx8ysB7Qwy/SVlJlAUNLxwKuBnxYVv4ZnJh1cSpItpioHHTOznFOaBqfWUo+IuA3YVWbTZcBfMX7W60XA1ZFYBwynWWMq8jUdM7MeUGdMmSpppGh9ZUSsrPUkSYuA0Yj4Qcm1o0pZZx6udCwHHTOz3Kt7SPTOiJjf0JGlI4G/JulamzAHHTOznCtMbZCRXwVmA4VWzkzg+5JOp76sM+P4mo6ZWd4pu5tDI2JTRDwvImZFxCySLrRTI+IRkowyb0tHsZ0BPJFmjanILR2zGlZvHGXF2i08tHuM6cNDLFswl8XzyiY2N+uYVrV0JF0DvJzk+s924OKIuLzC7jcCryXJDvMk8I5ax3fQMati9cZRlq36AfsOJAN2RnePsWzVDwAceKyrDLQo6kTEuTW2zyp6HMAFjRzf3WtmVXzo65sPBpyCfQeCD319c4dqZHYoT1dt1iMef3JfQ+VmHSFQTqardtAxM+sBzr1m1gOGhyY3VG7WGbVHrnVLUHLQMavig2edzOSSbovJA+KDZ53coRqZHUq0Lg1O1ty9ZlZFYYSah0xbV/M1HbPesXjeDAcZ63rd0n1Wi4OOmVkPcNAxM7M26Z6BArU46JiZ5ZwEysmwMAcdM7MeMDCQj6jjoGNm1lYHsjmsu9fMeoOzTFvXkwcSmPUEZ5m2vMjLNZ2cVNOsM5xl2vJAToNj1hucZdryolVBR9IVkh6VdHdR2QpJP5R0l6SvShou2rZc0lZJWyQtqHV8Bx0zs7wTDAwO1FzqdCWwsKTsJuBFEfFrwI+A5QCSTgKWACenz/lnSYPVDu6gY1aFs0xbPrSuey0ibgN2lZR9MyL2p6vrgJnp40XAtRHxVETcRzJt9enVju+gY1aFs0xbHjQwc+hUSSNFy9ImXu4PgG+kj2cADxZt256WVeTRa2ZVOMu05UL9Q6Z3RsT8pl9G+htgP/DFZo/hoGNWQzNZpiUdDlwNnAY8Brw5Iu6XNAVYBbwUuDIiLix6zreB44CxtOjVEfHoxN+B9YOsR6dJejvwOuDMiCgM6RwFji/abWZaVpGDjlkNdd4cekTJ+vnA4xFxoqQlwMeANwN7gA8AL0qXUm+JiJEWvwXrdelAgswOLy0E/gr47Yh4smjTGuBLkj4BTAfmALdXO5av6ZhVsXrjKMtv2MTo7jGC5ObQ5TdsYvXGQ37MDZesLwKuSh+vAs6UpIj4ZUR8lyT4mLVEA9d0ah9Lugb4HjBX0nZJ5wOfBp4D3CTpTkmfA4iIzcB1wD3AvwMXRETVPD+ZBx1JC9Px21slvb/M9sMlfTndvl7SrLR8iqRbJf1C0qdLnvPt9Jh3psvzsn4f1p9WrN3C2L7x36GxfQdYsXZL6a6HlawfvMCajvp5AphSx0v+a3pOf0Ddcjef5UBLR6+dGxHHRcTkiJgZEZdHxIkRcXxEvCRd3lW0/6UR8asRMTcivlHt2JBx0EnHa38GeA1wEnBuOq672MFuCOAykm4IeKYb4i8rHP4tRR+A+70tEw/tHmuofILeEhGnAL+ZLm8tt5OkpYXRRzt2PJZFPSyHNKCaSzfIuqVzOrA1IrZFxF7gWpJuh2LuhrCuNX14qN7yvSXrBy+wSpoEHEUyoKCiiBhN//058CUq3O8QESsjYn5EzJ82rZ7Gk/U8tS4jQdayDjr1jOHOrBti/C/CHY3X3vresgVzGZo8/gbrocmDLFswt3TX3SXra4Dz0sdnA7cUjfg5hKRJkqamjyeTjBK6u9L+Zodo1UWdjOV19NpbImJU0nOA60m6Ia4u3SkiVgIrAebPn1/xC29WSQP36eyRdAkwEhFrgMuBL0jaSnJ395LCjpLuB54LHCZpMfBq4AFgbRpwBoFvAf+S6ZuzniFgsEu6z2qpO+hIegGwDHh+8fMi4pVVnlbPGO7CPtub6YaQVOiGOCTomLVCvffpRMRFRY/3AOdU2G9WhUOc1kz9zAoDCfKgkZbOV4DPkfz6qnfquzuAOZJmkwSXJcDvlexT6Ib4HnV2QwDDEbGzqBviWw28DzOz3iIY6MGgsz8iPtvIwSNiv6QLgbUkXQZXRMRmd0OYmbWO6M2g83VJ7wa+CjxVKIyIXZWfAhFxI3BjSZm7IczMWqgXg05hJM6yorIATmhddczMrFFCDOZkvuq6g05EzM6yImbWrEYGZubj13AvE9nMxZSTwWu1g46kN1TbHhE3tK46ZmbWsPqnNui4elo6r6+yLQAHHTOzDuqpgQQR8Y52VMTMzJrXM0GnIJ2U6o3ALMbfHHpJ66tlZmb16qmWTpGvkeRF20DRkGkzM+u0Hhy9BsyMiIWZ1cTMzJqiFmYkkHQFSaaXRyPiRWnZMcCXSXq67gfeFBGPp8mWPwm8FngSeHtEfL/a8RsJjf9P0ikNvwMzM8vcgFRzqdOVQGkD4/3AzRExB7g5XYdkrrQ56bIUqJm1ppGg8xvAhnTGzrskbZJ0VwPPNzOzjLRqZoOIuI0kJVmx4nnPrgIWF5VfHYl1wLCk46odv5Hutdc0sK+ZmbVJAwMJpkoaKVpfmU4BU8uxEfFw+vgR4Nj0caU50x6mgkYyEjwAIOl5wBH1Ps/MzLJWd/fZzoiYP5FXioiQ1PT8ZHV3r0k6S9KPgfuA75BcTPpGsy9sZmatIcGgBmouE/CzQrdZ+u+jaXk9c6aN00gt/g44A/hRmoftTGBdA883M7OMtHAgQTnF06+fR3ILTaH8bUqcATxR1A1XViPXdPZFxGOSBiQNRMStkv6x4aqbmVlLtfLmUEnXAC8nuf6zHbgY+ChwnaTzSeY0e1O6+40kw6W3kgyZrpnBppGgs1vSs4HbgC9KehT4ZQPP7zqrN46yYu0WHto9xvThIZYtmFvXtMRmZt2lddNVR8S5FTadWWbfAC5o5Pj1ZJk+PCKeIhkatwf4c+AtwFFAblPgrN44yvIbNjG2L5l5e3T3GMtv2ATgwGNmudMzUxsA3wNOBT4XEW9Ny66qsn8urFi75WDAKRjbd4AVa7c46Ng4bhFbt5NgUg+lwTlM0u8BLys3t05e59N5aPdYQ+XWn9witrzopfl03kXSnTbMoXPr5HY+nenDQ4yWCTDTh4c6UBvrVm4RWx70VJbpiPgu8F1JIxFxeaX9JL0qIm5qae0ytGzB3HG/YAGGJg+ybMHcDtbKuk25HybVys06Y8JDotum7k7AagEn9bEJ1qWtFs+bwUfecAozhocQMGN4iI+84RT/erVxBit8kSuVm3WKpJpLN2hkyHQt3fGOGrB43gwHGavqQJTP9lGp3KwTWjm1QdZaGXT8LbSeM6PCtb8ZXXXtLx9/bCzxdGTTNZuX1nc+xtiZdciyBXMZmjw4rszX/qzbFAYSZJgGp2Va2dK5v4XHMusKhe5X36dj3a5nbg4td29OscJ9OhFRdT8zM8uKUE66Wetp6by+5PHXi9Zze5+OWT18c6jlQa/dp3Mwa6ikjcXrZr3ON4daLqiHutdKeISa9RXfHGp5IJjoJG1t08qBBGY9Z1Aqe09OXoanWv/omZaOpK/zTAvnBElrirdHxFlZVMysG/jmUMuLVmUckPTnwB+S/N3fRDIx23HAtcAUYAPw1ojY28zx62npfLzo8f9s5kXM8sotHcsDIQZaMHpN0gzgT4GTImJM0nXAEpLZQS+LiGslfQ44H/hsM69RsxMwIr5TbanjTSyUtEXSVknvL7P9cElfTrevlzQrLZ8i6VZJv5D06ZLnnCZpU/qcT6lbkgpZz3FLx/JiQLWXOk0ChiRNAo4EHgZeCaxKt18FLG62nvV0r22iygCCiPi1Ks8dBD4DvArYDtwhaU1E3FO02/nA4xFxoqQlJIlD30wyS+kHgBelS7HPAu8E1pPM0b0Q+Eat92LWqHykwbF+J9U9kGCqpJGi9ZURsbKwEhGjkj4O/BQYA75J0p22OyL2p7ttB5oeullPLV9Hcn/OWcBg+rh4qeZ0YGtEbEv7/64lmfa62CKemYl0FXCmJEXEL9NpFfYU7yzpOOC5EbEunZ/7aiYQdc2qecULpzVUXuAWvLVbnS2dnRExv2hZWXwMSUeT/E2eDUwHnkXyo7519ay1Q0Q8kC73A08VrT8QEQ/UePoM4MGi9XIR8uA+aSR9guRiVbVjbq9xTLOWuPWHO+otP6Jk/WALHriMZ6b+KLTg/7LMYQst+Dnp0tIvu/W2Fk1t8DvAfRGxIyL2kdz8/+vAcNrdBjATGG22nvkY2N0kSUsljUga2bGj/B8Ps2oamNZ8uGTdLXhrmxYm/PwpcIakI9OW9pnAPcCtwNnpPucBX2u2rjWDjqRTCwvJxaV5JWXVjALHF62Xi5AH90kj6VHAYzWOObPGMQGIiJWFZuS0adW7Q8zKqTR9eZnyw0rWM2vBj/8xVe2rYv1koI6llohYT/Ij6fskw6UHgJXA+4D3StpKch7XmtSzonqGTBcPk34E+ERxHUlGNVRyBzBH0mySwLAE+L2SfdaQRM7vkUTSW9JfemVFxMOS/lPSGSQDCd4G/FMd78OsYd04rXnaD78SYP78F3sYnQGtmxk0Ii4GLi4p3kZyjX7C6sm99opmDx4R+yVdCKwlGYRwRURslnQJMBIRa0gi5hfSCLqLJDABIOl+4LnAYZIWA69OR769G7gSGCIZteaRa5aJxfNmMPLALq5Z/yAHIhiUeONpZWecLb1RrtCC397qFrxZKQkm5SQlQV1pcCRNIWmhvDAtuhf4UkTsqvXciLiRZFhzcdlFRY/3AOdUeO6sCuUjHDqMumGrN456nhSravXGUa7fMHrwvpwDEVy/YZT5zz+m9FzZXfJUt+CtrfIytUE913T+K3A3cBrwI+DHwEuBuyW9sNpzu1khZf3o7jGCZ1LWr97oH5f2jGpZpkvskXSJpEJaqMuBKWkL/r3AwRuj0xb8J4C3S9ou6aR007uBzwNbgZ/gFrzVKRlI0LKbQzNVT0vn74D3RMR1xYWS3ghcCrwxi4plzSnrrR4NjF7rmha89aeemU8HOCUizi4tjIjrJf19BnVqi0b+mFj/ml4hI0GlUW3td4Cn4xd17z2gZ2dYF6vH02TzN6ZnuteAXza5ras1MBTW+tiyBXOZPDj+yzx5UB0dvWZWqte6154n6b1lygXk9uaXZQvmsuwrP2Df089c25084D8mVkbp5X8PUrZuIzE4kI97/eup5b8AzymzPJvkomd+lUb+LvklYN1jxdot436YAOx7OsoNJDDrGNGam0PboZ77dD5UaZukP2ttddpnxdot7DtQ8sfkQHgggY3j6aotL/IykGCiwa9ct1su+I+J1aPSZG2exM26TYsSfmaurptDq+iOd9EEzwhp9fAkbpYHhe61PJho0MntN89/TKweA8DTFcrNukaOBhLUM3PozykfXESS+8ysZ5ULONXKzTpB5KfbqZ6BBM9pR0XMzKx53XLNppaJdq+ZmVkXGMhJWycfnYAZmPO8ZzVUbv3p2OeUzs1WvdysU6TaS33H0bCkVZJ+KOleSf9d0jGSbpL04/Tfo5utZ98GnSf3lu+Vr1Ru/WnS4GBD5Wad0MLpqgE+Cfx7RLwQeDHJVDbvB26OiDnAzRRlTW9U3wYdJ/y0evg8sbxoRdCRdBTwW6TTUUfE3ojYDSwCrkp3uwpY3HQ9m31i3jnhp9XD54nlgRADdSzAVEkjRcvSkkPNBnYA/yppo6TPS3oWcGxEPJzu8whwbLN17dugs2zBXIYmj+8iGZo86ISfNs6sKeWDS6Vys45Q3RkJdkbE/KJlZcmRJgGnAp+NiHkkMwmM60pLZ8Bt+obGvg06i+fN4CNvOIUZw0MImDE8xEfecIrzrtk467Y93lC5Wae0aCDBdmB7RKxP11eRBKGfSToueR0dBzzabD37NugAjDywi0ee2EMAjzyxh5EHdnW6StZlnLnC8qLO7rWqIuIR4EFJhS6fM4F7gDXAeWnZecDXmq1n396n87erN/G/1/304PqBiIPrH158SqeqZV1GVE7HYdYtREvzRv4J8EVJhwHbgHeQNFCuk3Q+8ADwpmYP3rdB55r1D1Ysd9CxgiMPG+SXew+ULTfrJq3KSBARdwLzy2w6sxXH79ug424Tq0e5gFOt3Kwzumfqglr6Nuh4agOrx4Dg6TK/Q7plvnkz6K+pDXLrjBOO5j9+cujAgTNOaDq7g/WgcgGnWnn7DZB0vVt+ZJD1RE742fXuf6z8HeWVys3MuplyMrylb4OO05tYPYaHJrN7bF/ZcrNu0eLRa5nKSzdgyzm9idXjdS8+rqFys05pYcLPTPVt0HEaHKvHv931cEPlZp3SqqkNsta33WuFdDcr1m7hod1jTB8eYtmCuU6DY+M8/uShXWvVys06Qel/edC3QQeSwOMgY2a9oFu6z2rp66BjZtYr8hFyHHTMzHJPgsGBfFyid9AxM+sBeWnpZB4aJS2UtEXSVkmHzKst6XBJX063r5c0q2jb8rR8i6QFReX3S9ok6U5JI1m/BzOz7lZ7uHS3XPPJtKUjaRD4DPAqksmB7pC0JiLuKdrtfODxiDhR0hLgY8CbJZ0ELAFOBqYD35L0gogoZFp8RUTszLL+Zp7awPJA5CcjQdYtndOBrRGxLSL2AtcCi0r2WQRclT5eBZypJInQIuDaiHgqIu4DtqbHM2ubSinWuib1mlkqL/fpZB10ZgDFE9dsT8vK7hMR+4EngCk1nhvANyVtkLS00otLWippRNLIjh07JvRGrD8dfWT5dDeVys06ZaCO/+olaVDSRkn/J12fnV7+2JpeDmk6y2w+hjsc6jci4lTgNcAFkn6r3E4RsTIi5kfE/GnTprW3htYT9uwrP29OpXKzjlCdS/3eA9xbtP4x4LKIOBF4nOSySFOyDjqjwPFF6zPTsrL7SJoEHAU8Vu25EVH491Hgq7jbzTIytq98GvpK5QUeIGPtpjr+q+s40kzgd4HPp+sCXkly+QOSyyGLm61n1kHnDmBO2jQ7jGRgwJqSfdYA56WPzwZuiYhIy5ekX97ZwBzgdknPkvQcAEnPAl4N3J3x+zCr5YiS9YMDZIDLSH4pUjJAZiHwz+mAm4JXRMRLIqLcdMFmZSmdObTWAkwtXHJIl3KXJ/4R+CuemfhnCrA7vfwB5S+T1C3T0WsRsV/ShcBaYBC4IiI2S7oEGImINcDlwBckbQV2kXwhSfe7DrgH2A9cEBEHJB0LfDX9ACcBX4qIf8/yfVj/OvrIyWXzrJW5pjNcsr4I+GD6eBXw6dIBMsB96Xl/OvC9Flbb+lCdvWc7q/2gkfQ64NGI2CDp5a2p2XiZ3xwaETcCN5aUXVT0eA9wToXnXgpcWlK2DXhxK+q2euOoE35aVRe//mSWrfoB+w48M15t8qC4+PUnl+5aemF13AAZScUDZNYV7VdugEwA/ysiVparU/rrdCnAr/zK9GbelvWgFg2Z/nXgLEmvJWm9Pxf4JDAsaVLa2il3maRueR1IMGGrN46y/IZNjO4eI4DR3WMsv2ETqzc2/VlaD1o8bwYrzn4xM4aHEDBjeIgVZ784qx8nTQyQmZJFPSyHWnFzaEQsj4iZETGLpNfploh4C3AryeUPSC6HfK3ZevZtGpwVa7cwVjICaWzfAVas3eLWjo1TZzbyvSXrhYEw25sZICOpMEDmtgm/Aet5bbg59H3AtZI+DGwkuSzSlL5t6Xi6amux3SXrHiBjbVXnQIK6RcS3I+J16eNtEXF6RJwYEeek1ySb0rctnenDQ4yWCTCertpK1Xntb09nBsgEzo+QLwNk8zemSxIO1NS3QWfZgrksv2HTuC42T1dtpQrX/grnSeHaH3BI4OmWATLWjxpvyXRK33avLZ43g4+84ZRxF4g/8oZTfD3Hxql27c+sm7Tq5tCs9W1LBzxdtdXma3+WB1J+pqvu25aOWT2OGiqf2LNSuVmnuKVj1gMq/XjMyY9K6yPdElRqcdAxq2J3mRQ41crNOiUvP4TcvWZWRaUh9B5ab92l9XMbZMVBx6yKZQvmMjgw/ss6OCAPrbeuIlqTBqcd+rp7zQk/rZaRB3Zx4OnxN18eeDoYeWCXzxXrKnm5ptO3LZ3VG0d573V3jkv4+d7r7nTCTxvni+t/2lC5Wae0Og1OVvo26Lzv+rso+QHL05GUmxVEhQwzlcrNOiE/V3T6uHvtqf3lpxuuVG5m1s3y0r3Wt0HHzKx3dE/3WS0OOmZmeec0OGZm1i6FSdwmmgZH0vGSbpV0j6TNkt6Tlh8j6SZJP07/PbrZujromJn1hJYMJdgP/EVEnAScQTJt+knA+4GbI2IOcHO63hQHHTOz3BPJn/NaS3UR8XBEfD99/HPgXmAGsAi4Kt3tKmBxszX1NR0zsx7Q6tFrkmYB84D1wLER8XC66RHg2GaP66BjZtYT6iLhiQEAAAj2SURBVAo6UyWNFK2vjIiVhxxJejZwPfBnEfGfxSPjIiIkNX2nmoOOmVnuCTRYz447I2J+1SNJk0kCzhcj4oa0+GeSjouIhyUdBzzabE19TcfMrAe0aPSagMuBeyPiE0Wb1gDnpY/PA77WbD3d0jHLsQ0/2srAq3+37v3jm9/KsDZWjw+sv6r2Tk1pSRvi14G3Apsk3ZmW/TXwUeA6SecDDwBvavYFHHTMzHrCxAcSRMR3qxzozAm/AA46ZmY9oDBkuvs56JiZ9QA56JiZWXu4pWNmZm2Vj4SfDjpmZj3A3WtmZtZG+WjpZB4aJS2UtEXSVkmHZCaVdLikL6fb16f5fgrblqflWyQtqPeY9Tj6yMkNlZuZdS+B6li6QKZBR9Ig8BngNcBJwLlpmuxi5wOPR8SJwGXAx9LnngQsAU4GFgL/LGmwzmPW9PiT+xoqNzPrVsnEBYM1l26QdUvndGBrRGyLiL3AtSQpsosVp8xeBZyZpmJYBFwbEU9FxH3A1vR49RzTzKzPtGQ+ncxlHXRmAA8WrW9Py8ruExH7gSeAKVWeW88xAZC0VNKIpJEdO3ZM4G2YmXWz1syn0w7dUYuMRMTKiJgfEfOnTZvW6eqYmWUoHy2drEevjQLHF63PTMvK7bNd0iTgKOCxGs+tdUwzs76SlyHTWdfyDmCOpNmSDiMZGLCmZJ/ilNlnA7dERKTlS9LRbbOBOcDtdR6zpvs/Wj4zb6Vy608+Tywf6mnl9EFLJyL2S7oQWAsMAldExGZJlwAjEbGGZO6GL0jaCuwiCSKk+10H3APsBy6IiAMA5Y7ZTP38h8Pq4fPE8qE7RqfVkvnNoRFxI3BjSdlFRY/3AOdUeO6lwKX1HNPMrJ+pS+7DqcUZCczMcq97us9qyceVJ7Pu919KCzqVbcP6VWuGTGd9DjromLXGMd2SbcP61cQHErTjHHTQMWuNXTjbhnWMWpUGJ/NzsG+u6WzYsGGnpAcqbJ4K7GxnfSrolnpA99SlW+oB4+tyNPBcoHBOzaVGtg1Jxdk21hXtV5xVozTbxn8rrYSkpcDSdPUpbrr37nrfgFQ2eUezOvX/ppPnRKdee261jRs23LVWmjG1juMcIWmkaH1lRKwsWi+X8eWQc3Ai+iboRETFlASSRiJifjvr0831gO6pS7fUA8bXRdLZwMKI+MN0/a20+MtZSfpHYmVpndqtU6/dr++52vaIWNiuukyUu9fMmtNItg3qzLZRzzHNspT5OeigY9acrs22YTYBmZ+DfdO9VsPK2ru0RbfUA7qnLt1SDyiqSxdl2+jk59Op1/Z7zkil87qVr6Hkh5eZmVn23L1mZmZt46BjZmZt09NBp1Y6h2bSlGRYl/dKukfSXZJulvT8om0HJN2ZLhO6qFdHPd4uaUfR6/1h0bbzJP04Xc4rfW4GdbmsqB4/krS7aFsrP5MrJD0qqez9Lkp8Kq3nXZJOLdrW0s+k5HU7cv528lzt1PnZqXOxW8+9TEVETy4kF8F+ApwAHAb8ADipZJ93A59LHy8Bvpw+Pind/3BgdnqcwYzr8grgyPTxHxfqkq7/oo2fyduBT5d57jHAtvTfo9PHR2dZl5L9/4TkomZLP5P0WL8FnArcXWH7a4FvkOQROQNYn8Vn0g3nbyfP1U6dn508F7vx3Mt66eWWTj3pHBpNU5JZXSLi1oh4Ml1dRzI+vtUmkuJiAXBTROyKiMeBm0jyhrWrLucC10zg9SqKiNtIRpdVsgi4OhLrgGFJx9H6z6RYp87fTp6rnTo/O3Yudum5l6leDjrl0jlUTVMCFKcpqfXcVtel2Pkkv24KjpA0ImmdpMVtqMcb06b8KkmFG8U69pmk3TezgVuKilv1mdSjUl1b/ZnU85pl92nh+dvJc7VT52c3n4udOPcy5ft0uoyk3wfmA79dVPz8iBiVdAJwi6RNEfGTjKrwdeCaiHhK0h+R/JJ+ZUavVa8lwKpI72VJtfMzsTI6dK52+vz0uThBvdzSySJNSZZ1QdLvAH8DnBURTxXKI2I0/Xcb8G1gXlb1iIjHil7788BpjbyHVtalyBJKujNa+JnUoxNpazp1/nbyXO3U+dnN52LvpUzq9EWlrBaSVtw2kqZw4eLgySX7XMD4C7HXpY9PZvyF2G1MbCBBPXWZR3Ixc05J+dHA4enjqcCPqXKRswX1OK7o8f8A1qWPjwHuS+tzdPr4mCw/k3S/FwL3k97I3OrPpOiYs6h8Mfd3GX8x9/YsPpNuOH87ea526vzs9LnYbede1kvHK5Dpm0tGfvwo/YL8TVp2CcmvM4AjgK+QXGi9HTih6Ll/kz5vC/CaNtTlW8DPgDvTZU1a/jJgU/pF2AScn3E9PgJsTl/vVuCFRc/9g/Sz2gq8I+vPJF3/IPDRkue1+jO5BngY2EfSN34+8C7gXel2kUxs9ZP09eZn9Zl0w/nbyXO1U+dnp87Fbj33slycBsfMzNqml6/pmJlZl3HQMTOztnHQMTOztnHQMTOztnHQMTOztnHQ6WOSPijpLztdD7NSPjd7l4OOmZm1jYNOH5H0tjRR4g8kfaFk2zsl3ZFuu17SkWn5OZLuTstvS8tOlnR7On/IXZLmdOL9WO/wudk/fHNon5B0MvBV4GURsVPSMcCfkswF8nFJUyLisXTfDwM/i4h/krQJWBhJQsPhiNgt6Z9I0o98UdJhJClWxjr13izffG72F7d0+scrga9ExE6AiCidw+NFkv5v+kV+C0n+LoD/AK6U9E6Sya4Avgf8taT3kWTY9ZfaJsLnZh9x0LGCK4ELI+IU4EMkeb2IiHcBf0uS0XZD+qvzS8BZwBhwo6ROT31gve1KfG72DAed/nELcI6kKQBpF0ax5wAPS5pM8muSdL9fjYj1EXERsAM4Pp03ZFtEfAr4GvBrbXkH1qt8bvYRT+LWJyJis6RLge9IOgBsJEnTXvABYD3Jl3c9yRcdYEV6MVbAzSTZdN8HvFXSPuAR4O/b8iasJ/nc7C8eSGBmZm3j7jUzM2sbBx0zM2sbBx0zM2sbBx0zM2sbBx0zM2sbBx0zM2sbBx0zM2ub/w9J98WFHonFygAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "col_names = AEEEM_EQ.columns\n",
        "plot_two_columns(AEEEM_EQ, 'class', col_names[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7657XO-cbITA"
      },
      "source": [
        "### NASA\n",
        "\n",
        "\n",
        "*   variable name_1, variable range (will be standardized in our analysis)\n",
        "*   List item\n",
        "\n",
        "\n",
        "#### Show them examples from the data\n",
        "correlation between our two favourite metrics?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjMo4pvMxFCt"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import io\n",
        "\n",
        "    \n",
        "url = \"https://raw.githubusercontent.com/anonymous-replication/replication-nasa/master/data/processed/CM1-processed.csv\" \n",
        "download = requests.get(url).content\n",
        "NASA_CM1 = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/anonymous-replication/replication-nasa/master/data/processed/KC3-processed.csv\" \n",
        "download = requests.get(url).content\n",
        "NASA_KC3 = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/anonymous-replication/replication-nasa/master/data/processed/MC2-processed.csv\" \n",
        "download = requests.get(url).content\n",
        "NASA_MC2 = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/anonymous-replication/replication-nasa/master/data/processed/MW1-processed.csv\" \n",
        "download = requests.get(url).content\n",
        "NASA_MW1 = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/anonymous-replication/replication-nasa/master/data/processed/PC1-processed.csv\" \n",
        "download = requests.get(url).content\n",
        "NASA_PC1 = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/anonymous-replication/replication-nasa/master/data/processed/PC2-processed.csv\" \n",
        "download = requests.get(url).content\n",
        "NASA_PC2 = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/anonymous-replication/replication-nasa/master/data/processed/PC3-processed.csv\" \n",
        "download = requests.get(url).content\n",
        "NASA_PC3 = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/anonymous-replication/replication-nasa/master/data/processed/PC4-processed.csv\" \n",
        "download = requests.get(url).content\n",
        "NASA_PC4 = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AcmP_r5EKR0"
      },
      "outputs": [],
      "source": [
        "drop_list = []\n",
        "drop_variables(NASA_CM1, drop_list)\n",
        "drop_variables(NASA_KC3, drop_list)\n",
        "drop_variables(NASA_MC2, drop_list)\n",
        "drop_variables(NASA_MW1, drop_list)\n",
        "drop_variables(NASA_PC1, drop_list)\n",
        "drop_variables(NASA_PC2, drop_list)\n",
        "drop_variables(NASA_PC3, drop_list)\n",
        "drop_variables(NASA_PC4, drop_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbJ6rKv_ELAE"
      },
      "outputs": [],
      "source": [
        "numerical_response(NASA_CM1, 'NASA') \n",
        "numerical_response(NASA_KC3, 'NASA') \n",
        "numerical_response(NASA_MC2, 'NASA') \n",
        "numerical_response(NASA_MW1, 'NASA') \n",
        "numerical_response(NASA_PC1, 'NASA') \n",
        "numerical_response(NASA_PC2, 'NASA') \n",
        "numerical_response(NASA_PC3, 'NASA') \n",
        "numerical_response(NASA_PC4, 'NASA') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--sHeQZp20yR"
      },
      "outputs": [],
      "source": [
        "\n",
        "project_dict_NASA = {\n",
        "  \"NASA CM1 \": NASA_CM1,\n",
        "  \"NASA KC3 \": NASA_KC3,\n",
        "  \"NASA MC2 \": NASA_MC2, \n",
        "  \"NASA MW1 \": NASA_MW1, \n",
        "  \"NASA PC1 \": NASA_PC1,\n",
        "  \"NASA PC2 \": NASA_PC2,\n",
        "  \"NASA PC3 \": NASA_PC3,\n",
        "  \"NASA PC4 \": NASA_PC4}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka9809oZcNSp"
      },
      "source": [
        "### PROMISE\n",
        "\n",
        "\n",
        "*   variable name_1, variable range (will be standardized in our analysis)\n",
        "*   List item\n",
        "\n",
        "\n",
        "#### Show them examples from the data\n",
        "correlation between our two favourite metrics?\n",
        "\n",
        "number of bugs - > buggy dataset classify as buggy instead of number of bugs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDhjfhTAoqxW"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/feiwww/PROMISE-backup/master/bug-data/camel/camel-1.6.csv\" \n",
        "download = requests.get(url).content\n",
        "PROMISE_Camel_v_1_6 = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/feiwww/PROMISE-backup/master/bug-data/ivy/ivy-1.2.csv\" \n",
        "download = requests.get(url).content\n",
        "PROMISE_IVY_1_2 = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/feiwww/PROMISE-backup/master/bug-data/jedit/jedit-4.0.csv\" \n",
        "download = requests.get(url).content\n",
        "PROMISE_Jedit_v_4_0 = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/feiwww/PROMISE-backup/master/bug-data/log4j/log4j-1.0.csv\" \n",
        "download = requests.get(url).content\n",
        "PROMISE_Log4j_v_1_0 = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/feiwww/PROMISE-backup/master/bug-data/lucene/lucene-2.4.csv\" \n",
        "download = requests.get(url).content\n",
        "PROMISE_Lucene_v_2_4 = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/feiwww/PROMISE-backup/master/bug-data/poi/poi-3.0.csv\" \n",
        "download = requests.get(url).content\n",
        "PROMISE_POI_v_3_0 = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/feiwww/PROMISE-backup/master/bug-data/xalan/xalan-2.6.csv\" \n",
        "download = requests.get(url).content\n",
        "PROMISE_Xalan_v_2_6 = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/feiwww/PROMISE-backup/master/bug-data/xerces/xerces-1.3.csv\" \n",
        "download = requests.get(url).content\n",
        "PROMISE_Xerces_v_1_3 = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
        "\n",
        "drop_list = 'name'\n",
        "drop_variables(PROMISE_Camel_v_1_6, drop_list)\n",
        "drop_variables(PROMISE_IVY_1_2, drop_list)\n",
        "drop_variables(PROMISE_Jedit_v_4_0, drop_list)\n",
        "drop_variables(PROMISE_Log4j_v_1_0, drop_list)\n",
        "drop_variables(PROMISE_Lucene_v_2_4, drop_list)\n",
        "drop_variables(PROMISE_POI_v_3_0, drop_list)\n",
        "drop_variables(PROMISE_Xalan_v_2_6, drop_list)\n",
        "drop_variables(PROMISE_Xerces_v_1_3, drop_list)\n",
        "\n",
        "numerical_response(PROMISE_Camel_v_1_6, 'PROMISE')\n",
        "numerical_response(PROMISE_IVY_1_2, 'PROMISE')\n",
        "numerical_response(PROMISE_Jedit_v_4_0, 'PROMISE')\n",
        "numerical_response(PROMISE_Log4j_v_1_0, 'PROMISE') \n",
        "numerical_response(PROMISE_Lucene_v_2_4, 'PROMISE')\n",
        "numerical_response(PROMISE_POI_v_3_0, 'PROMISE')\n",
        "numerical_response(PROMISE_Xalan_v_2_6, 'PROMISE') \n",
        "numerical_response(PROMISE_Xerces_v_1_3, 'PROMISE') \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUZ-b4uX2rRw"
      },
      "outputs": [],
      "source": [
        "# ADD THE PROJECTS TO A DICTIONARY\n",
        "\n",
        "project_dict_PROMISE = {\n",
        "  \"PROMISE Camel v1.6 \": PROMISE_Camel_v_1_6,\n",
        "  \"PROMISE IVY v1.2 \": PROMISE_IVY_1_2,\n",
        "  \"PROMISE Jedit v4.0 \": PROMISE_Jedit_v_4_0,\n",
        "  \"PROMISE Log4j v1.0 \": PROMISE_Log4j_v_1_0,\n",
        "  \"PROMISE Lucene v2.4 \": PROMISE_Lucene_v_2_4,\n",
        "  \"PROMISE POI v3.0 \": PROMISE_POI_v_3_0,\n",
        "  \"PROMISE Xalan v2.6 \": PROMISE_Xalan_v_2_6,\n",
        "  \"PROMISE Xerces v1.3 \": PROMISE_Xerces_v_1_3\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xbDxiaKe9KR"
      },
      "source": [
        "# recreate table 1 \n",
        "\n",
        "| Dataset | Project | # of Entities | # of Defective | % Defective |\n",
        "| :- | :- | -: | -: | -: | \n",
        "| AEEEM | Eclipse JDT Core | 997 | 206 | 20.7 % |\n",
        "| AEEEM | Equinox  | 324 | 129 | 39.8 % |\n",
        "| AEEEM | Apache Lucene  | 691 | 64 | 9.3 % |\n",
        "| AEEEM | Mylyn  | 1862 | 245 | 13.2 % |\n",
        "| AEEEM | Eclipse PDE UI  | 778 | 117 | 15.0 % |\n",
        "| NASA | CM1  | 505 | 48 | 9.5 % |\n",
        "| NASA | KC3  | 458 | 43 | 9.4 % |\n",
        "| NASA | MC2  | 161 | 52 | 32.3 % |\n",
        "| NASA | MW1  | 403 | 31 | 7.7 % |\n",
        "| NASA | PC1  | 1107 | 76 | 6.9 % |\n",
        "| NASA | PC2  | 5589 | 23 | 0.4 % |\n",
        "| NASA | PC3  | 1563 | 160 | 10.2 % |\n",
        "| NASA | PC4  | 1458 | 178 | 12.2 % |\n",
        "| Promise | Camel v1.6  | 965 | 188 | 19.5 % |\n",
        "| Promise | IVY 1.2  | 352 | 40 | 11.4 % |\n",
        "| Promise | Jedit v4.0  | 306 | 75 | 24.5 % |\n",
        "| Promise | Log4j v1.0  | 135 | 34 | 25.2 % |\n",
        "| Promise | Lucene v2.4  | 340 | 203 | 59.7 % |\n",
        "| Promise | POI v3.0  | 442 | 281 | 63.6 % |\n",
        "| Promise | Xalan v2.6  | 885 | 411 | 46.4 % |\n",
        "| Promise | Xerces v1.3  | 453 | 69 | 15.2 % |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsdQ-2TgQfLO"
      },
      "source": [
        "# Supervised classifiers\n",
        "\n",
        "\n",
        "*   Random forest \n",
        "*   Naive Bayes \n",
        "*   Logistic regression\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "For the supervised classifiers, we need training data. To predict defects in a target project we fit a model on all the remaining projects and use the average AUC score for that specific supervised classifier. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0HIvIfYY3EK"
      },
      "source": [
        "## Random forest \n",
        "\n",
        "## Short description\n",
        "\n",
        "Random Forest is a supervised classifier that mitigates some of the difficulties with normal decision trees. Normal decision trees are said to have a higher variance as they are sensitive to training data cf. the algorithms preference for pure nodes. Random Forest mitigates this by creating a “forest” of decision-trees using boot-strapped datasets from the training data. The decided number of new trees are all built on random combinations of the original rows and columns. That is, bootstrapping is applied to decrease the sensitivity to training data and random-feature-selection is used to decrease correlation between our trees and thus decreases the variance of our ML algorithm. To consider test data, the algorithm uses aggregation for majority vote classification to predict, in this case, whether or not the software is defect. \n",
        "\n",
        "\n",
        "\n",
        "## Tuning parameters\n",
        "short discussion\n",
        "\n",
        "It is common practice to use the square root of the total features per tree.\n",
        "\n",
        "\n",
        "justify the ones we ended up with \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDr-AQL0cIL-"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "\n",
        "def random_forest(df_train, df_test):\n",
        "    '''\n",
        "    \n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df_train : TYPE\n",
        "        DESCRIPTION.\n",
        "    df_test : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    y_pred : TYPE\n",
        "        DESCRIPTION.\n",
        "    y_test : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    '''\n",
        "    y_train = list(df_train['class'])\n",
        "    y_test = list(df_test['class'])\n",
        "    scaled_train_X, scaled_test_X = scale_data(df_train, df_test) \n",
        "     \n",
        "    param_grid = { \n",
        "        'n_estimators': [70, 150, 200],\n",
        "        'max_features': ['auto', 'sqrt', 'log2'],\n",
        "        'max_depth' : [4,5,6,7,8],\n",
        "        'criterion' : ['entropy', 'gini'],\n",
        "        'class_weight' : ['balanced']}\n",
        "\n",
        "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=7)\n",
        "\n",
        "    rfc = RandomForestClassifier(random_state=7)\n",
        "    CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=cv, scoring = 'roc_auc')\n",
        "    CV_rfc.fit(scaled_train_X, y_train)\n",
        "    rfc_best = RandomForestClassifier(**CV_rfc.best_params_)\n",
        "    rfc_best.fit(scaled_train_X, y_train)\n",
        "    y_pred = rfc_best.predict(scaled_test_X)\n",
        "    print(CV_rfc.best_params_)\n",
        " \n",
        "    return y_pred, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vQ1_-sz094q",
        "outputId": "b58251b5-34d7-437a-d949-80b8d7aaa378"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'class_weight': {0: 0.5, 1: 2}, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'n_estimators': 70}\n",
            "{'class_weight': {0: 0.5, 1: 2}, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'n_estimators': 70}\n",
            "{'class_weight': {0: 0.5, 1: 2}, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'n_estimators': 150}\n",
            "{'class_weight': {0: 0.5, 1: 2}, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'n_estimators': 150}\n",
            "\n",
            "AUC score for Eclipse JDT Core, AEEEM_JDT   : 0.57\n",
            "{'class_weight': {0: 0.5, 1: 2}, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'n_estimators': 150}\n",
            "{'class_weight': {0: 0.5, 1: 2}, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'n_estimators': 70}\n",
            "{'class_weight': {0: 0.5, 1: 2}, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'n_estimators': 150}\n",
            "{'class_weight': {0: 0.5, 1: 2}, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'n_estimators': 150}\n",
            "\n",
            "AUC score for Equinox, AEEEM_EQ  : 0.56\n",
            "{'class_weight': {0: 0.5, 1: 2}, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'n_estimators': 150}\n",
            "{'class_weight': {0: 0.5, 1: 2}, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'n_estimators': 70}\n",
            "{'class_weight': {0: 0.5, 1: 2}, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'n_estimators': 150}\n",
            "{'class_weight': {0: 0.5, 1: 2}, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'n_estimators': 150}\n",
            "\n",
            "AUC score for Apache Lucene , AEEEM_LC  : 0.62\n",
            "{'class_weight': {0: 0.5, 1: 2}, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'n_estimators': 150}\n",
            "{'class_weight': {0: 0.5, 1: 2}, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'n_estimators': 70}\n",
            "{'class_weight': {0: 0.5, 1: 2}, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'n_estimators': 70}\n",
            "{'class_weight': {0: 0.5, 1: 2}, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'n_estimators': 150}\n",
            "\n",
            "AUC score for Mylyn, AEEEM_ML : 0.56\n",
            "{'class_weight': {0: 0.5, 1: 2}, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'n_estimators': 150}\n",
            "{'class_weight': {0: 0.5, 1: 2}, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'n_estimators': 70}\n",
            "{'class_weight': {0: 0.5, 1: 2}, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'n_estimators': 70}\n",
            "{'class_weight': {0: 0.5, 1: 2}, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'n_estimators': 150}\n",
            "\n",
            "AUC score for Eclipse PDE UI, AEEEM_PDE  : 0.58\n",
            "\n",
            "Mean AUC score for all projects: 0.58\n"
          ]
        }
      ],
      "source": [
        "get_auc_scores(project_dict_AEEEM, random_forest, average_AUC_cross)\n",
        "\n",
        "#get_auc_scores(project_dict_NASA, random_forest, average_AUC_cross)\n",
        "\n",
        "#get_auc_scores(project_dict_PROMISE, random_forest, average_AUC_cross)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xh_kLKM0-Pi"
      },
      "outputs": [],
      "source": [
        "#get_auc_scores(project_dict_AEEEM, random_forest, average_AUC_within)\n",
        "\n",
        "#get_auc_scores(project_dict_NASA, random_forest, average_AUC_within)\n",
        "\n",
        "#get_auc_scores(project_dict_PROMISE, random_forest, average_AUC_within)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1ruFUtVY45l"
      },
      "source": [
        "## Naive Bayes\n",
        "\n",
        "## Short description\n",
        "\n",
        "Naive Bayes is a supervised classifier which classifies entities based on probabilities. Probabilities are calculated “naively” by assuming all features are independent from one another. While this may often not reflect reality, it is computationally less demanding than complex models and Naive Bayes tends to perform well. As a result, the authors and many others use is for completeness and it provides a meaningful benchmark to the spectral clustering. Naive Bayes works by computing the conditional probability for each feature. That is, the probability of the feature being true given that the software is defect. Naive Bayes is thus often computed over binary variables, but packages also allow for computing on continuous variables assuming a gaussian distribution or by categorizing the observations into discrete bins.\n",
        "\n",
        "\n",
        "\n",
        "## Tuning parameters\n",
        "short discussion\n",
        "\n",
        "justify the ones we ended up with \n",
        "\n",
        "she told us that our data set is not normal distributed (do you also remeber that?) so are we going the right thing by using gaussian NB?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KKB80s2EDam"
      },
      "outputs": [],
      "source": [
        "'''Here I am using the gaussianNB WITHOUT standardizing the data. It provides the highest AUC score'''\n",
        "\n",
        "\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "\n",
        "\n",
        "def naive_bayes(df_train, df_test):\n",
        "    y_train = list(df_train['class'])\n",
        "    y_test = list(df_test['class'])\n",
        "    X_train = df_train.iloc[:,:-1]\n",
        "    X_test = df_test.iloc[:,:-1]\n",
        "    # class_prior\n",
        "    \n",
        "    prob1 = sum(y_train)/len(y_train)\n",
        "    prob0 = 1 - prob1\n",
        "    \n",
        "    cnb = ComplementNB(alpha = prob1, class_prior = ((prob0, prob1)))\n",
        "    cnb.fit(X_train, y_train)\n",
        "    y_pred = cnb.predict(X_test)\n",
        "    return y_pred, y_test\n",
        "\n",
        "auc = get_auc_scores(project_dict_AEEEM, naive_bayes, average_AUC_within)\n",
        "\n",
        "# suggest not scaling \n",
        "# ComplementNB used for unbalanced data sets\n",
        "# remove correlated variables ?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12U49ghs1Foq",
        "outputId": "631d5f75-ab4d-40c2-bdc0-7a4ca98f957f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "AUC score for Eclipse JDT Core, AEEEM_JDT   : 0.93\n",
            "\n",
            "AUC score for Equinox, AEEEM_EQ  : 0.96\n",
            "\n",
            "AUC score for Apache Lucene , AEEEM_LC  : 0.96\n",
            "\n",
            "AUC score for Mylyn, AEEEM_ML : 0.86\n",
            "\n",
            "AUC score for Eclipse PDE UI, AEEEM_PDE  : 0.95\n",
            "\n",
            "Mean AUC score for all projects: 0.93\n"
          ]
        }
      ],
      "source": [
        "get_auc_scores(project_dict_AEEEM, naive_bayes, average_AUC_cross)\n",
        "\n",
        "#get_auc_scores(project_dict_NASA, naive_bayes, average_AUC_cross)\n",
        "\n",
        "#get_auc_scores(project_dict_PROMISE, naive_bayes, average_AUC_cross)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wIlLHdu1GBK",
        "outputId": "c38051fe-e645-40cc-89c3-1ded7ca068e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "AUC score for Eclipse JDT Core, AEEEM_JDT   : 0.89\n",
            "\n",
            "AUC score for Equinox, AEEEM_EQ  : 1.0\n",
            "\n",
            "AUC score for Apache Lucene , AEEEM_LC  : 1.0\n",
            "\n",
            "AUC score for Mylyn, AEEEM_ML : 1.0\n",
            "\n",
            "AUC score for Eclipse PDE UI, AEEEM_PDE  : 1.0\n",
            "\n",
            "Mean AUC score for all projects: 0.98\n"
          ]
        }
      ],
      "source": [
        "get_auc_scores(project_dict_AEEEM, naive_bayes, average_AUC_within)\n",
        "\n",
        "#get_auc_scores(project_dict_NASA, naive_bayes, average_AUC_within)\n",
        "\n",
        "#get_auc_scores(project_dict_PROMISE, naive_bayes, average_AUC_within)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-4jGdsiY6pv"
      },
      "source": [
        "## Logistic regression\n",
        "## Short description\n",
        "\n",
        "Logistic Regression is a supervised classifier that uses probability to predict the label of an entity. Firstly, multiple linear regression is used to find the weight of each predictor variable. When the goal is to classify binary variables, as opposed to continuous variables, it makes little sense to talk about a linear effect of changing the predictor values. Rather, it makes sense to investigate how much the probability of software being defect changes when a predictor’s value changes. Ultimately, logistic regression provides an approach to classify or prioritize among variables based on their probability to be e.g. defect.\n",
        "\n",
        "To transform this multi-linear relationship, the sigmoid function is often applied:\n",
        "$$\n",
        "p = \\frac{e^{ x \\vec{\\beta}}}{1+e^x \\vec{\\beta}}, \\quad x \\vec{\\beta} = \\beta_0 + x_1 \\beta_1 + ... + x_p \\beta_p, \n",
        "$$ \n",
        "where $x_i$ is the i-th column.             \n",
        "The sigmoid function above tells us that the probability of defect software is increasing in x and approaches 1 (that is, 100%) as x goes up. X is the beta-estimator of each predictor-variable. A threshold is then passed to the logistic regression to decide at which probabilities the observation should be classified as true/false. This is a meaningful difference to linear regression which merely fits a line (or plane) through the datapoints to minimize the squared errors but does not help classifying. \n",
        "\n",
        "\n",
        "///As with other supervised classifiers, the logistic regression is a serious contender for datasets with much training data. However, as the authors emphasize, software defect prediction is typically not based on large amounts of data. Rather on smaller individual projects with heterogeneous metrics that makes it infeasible and suboptimal to train models to predict the defects. It is nonetheless interesting to compare the performance of the logistic regression to proxy what could be expected to be achieved, ceteris paribus, if data was fully available. Thereby assessing whether spectral clustering underperforms or not. [this is loosely written and we should definitely cut down but I wanted to have too much rather than too little]///\n",
        "\n",
        "\n",
        "## Tuning parameters\n",
        "short discussion\n",
        "\n",
        "justify the ones we ended up with \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0LCCNMkvY9Zi"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def LR(df_train, df_test):\n",
        "    y_train = list(df_train['class'])\n",
        "    y_test = list(df_test['class'])\n",
        "    scaled_train_X, scaled_test_X = scale_data(df_train, df_test)\n",
        "    # scaled_train_X = df_train.iloc[:,:-1]\n",
        "    # scaled_test_X = df_test.iloc[:,:-1]\n",
        "\n",
        "    model = LogisticRegression(random_state=0, max_iter = 500)\n",
        "    model.fit(scaled_train_X, y_train)\n",
        "\n",
        "\n",
        "    y_pred = model.predict(scaled_test_X)\n",
        "    y_test = y_test\n",
        "    return y_pred, y_test\n",
        "\n",
        "    # df_result_training = pd.DataFrame([y_test, y_pred])\n",
        "    # df_result_training = df_result_training.T\n",
        "    # df_result_training.columns = [\"Label_GT\", \"Label_Pred\"]\n",
        "    # df_result_training.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-U9Qr_g4gn6"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def LR(df_train, df_test):\n",
        "    from sklearn.datasets import make_blobs\n",
        "    from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "    from sklearn.model_selection import GridSearchCV\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    #Model data\n",
        "    y_train = list(df_train['class'])\n",
        "    y_test = list(df_test['class'])\n",
        "    scaled_train_X, scaled_test_X = scale_data(df_train, df_test)\n",
        "    \n",
        "    #Applt these if we want to try without scaling the data:\n",
        "    #scaled_train_X = df_train.iloc[:,:-1]\n",
        "    #scaled_test_X = df_test.iloc[:,:-1]\n",
        "\n",
        "    #Model and parameters:\n",
        "    model = LogisticRegression()\n",
        "    solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "    penalty = ['l2']\n",
        "    c_values = [100, 10, 1.0, 0.1, 0.01]\n",
        "\n",
        "    #Define grid search\n",
        "    grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
        "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=0)\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='roc_auc',error_score=0)\n",
        "    grid_result = grid_search.fit(scaled_train_X, y_train)\n",
        "    \n",
        "    #Summarize Results\n",
        "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "    means = grid_result.cv_results_['mean_test_score']\n",
        "    stds = grid_result.cv_results_['std_test_score']\n",
        "    params = grid_result.cv_results_['params']\n",
        "    for mean, stdev, param in zip(means, stds, params):\n",
        "      print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "\n",
        "    \n",
        "    y_pred = grid_result.predict(scaled_test_X)\n",
        "    y_test = y_test\n",
        "    return y_pred, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQGC48qm1W2r",
        "outputId": "b73abcd1-500c-4691-e9ef-640c182c58b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.850997 using {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.834024 (0.025295) with: {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.833116 (0.025670) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.834055 (0.025298) with: {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.833182 (0.025436) with: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.833128 (0.025756) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.833355 (0.025490) with: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.832942 (0.028030) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.832891 (0.028026) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.833157 (0.027977) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.848079 (0.032905) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.848100 (0.032940) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.850997 (0.031045) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.844230 (0.031360) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.844230 (0.031340) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.846793 (0.029747) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.6319022063208111\n"
          ]
        }
      ],
      "source": [
        "\n",
        "y_pred, y_test = LR(AEEEM_JDT, AEEEM_EQ)\n",
        "AUC = roc_auc_score(y_test, y_pred)\n",
        "print(AUC)\n",
        "\n",
        "#get_auc_scores(project_dict_AEEEM, LR, average_AUC_cross)\n",
        "\n",
        "#get_auc_scores(project_dict_NASA, LR, average_AUC_cross)\n",
        "\n",
        "#get_auc_scores(project_dict_PROMISE, LR, average_AUC_cross)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC9iXzIZ1Wp_",
        "outputId": "82ed9ec3-b50e-4580-d33b-54089850c86a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "AUC score for Eclipse JDT Core, AEEEM_JDT   : 0.7\n",
            "\n",
            "AUC score for Equinox, AEEEM_EQ  : 0.7\n",
            "\n",
            "AUC score for Apache Lucene , AEEEM_LC  : 0.61\n",
            "\n",
            "AUC score for Mylyn, AEEEM_ML : 0.58\n",
            "\n",
            "AUC score for Eclipse PDE UI, AEEEM_PDE  : 0.58\n",
            "\n",
            "Mean AUC score for all projects: 0.63\n",
            "\n",
            "AUC score for NASA CM1  : 0.55\n",
            "\n",
            "AUC score for NASA KC3  : 0.58\n",
            "\n",
            "AUC score for NASA MC2  : 0.6\n",
            "\n",
            "AUC score for NASA MW1  : 0.58\n",
            "\n",
            "AUC score for NASA PC1  : 0.55\n",
            "\n",
            "AUC score for NASA PC2  : 0.52\n",
            "\n",
            "AUC score for NASA PC3  : 0.55\n",
            "\n",
            "AUC score for NASA PC4  : 0.75\n",
            "\n",
            "Mean AUC score for all projects: 0.58\n",
            "\n",
            "AUC score for PROMISE Camel v1.6  : 0.55\n",
            "\n",
            "AUC score for PROMISE IVY v1.2  : 0.58\n",
            "\n",
            "AUC score for PROMISE Jedit v4.0  : 0.64\n",
            "\n",
            "AUC score for PROMISE Log4j v1.0  : 0.71\n",
            "\n",
            "AUC score for PROMISE Lucene v2.4  : 0.68\n",
            "\n",
            "AUC score for PROMISE POI v3.0  : 0.73\n",
            "\n",
            "AUC score for PROMISE Xalan v2.6  : 0.72\n",
            "\n",
            "AUC score for PROMISE Xerces v1.3  : 0.64\n",
            "\n",
            "Mean AUC score for all projects: 0.66\n"
          ]
        }
      ],
      "source": [
        "get_auc_scores(project_dict_AEEEM, LR, average_AUC_within)\n",
        "\n",
        "get_auc_scores(project_dict_NASA, LR, average_AUC_within)\n",
        "\n",
        "get_auc_scores(project_dict_PROMISE, LR, average_AUC_within)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fBO3XAXfi6q"
      },
      "source": [
        "# Unsupervised classifiers\n",
        "\n",
        "Does not require training data, therefore avoids the heterogenety problem.\n",
        "Distance based clustering methods: \n",
        "* K-means clustering (KM)\n",
        "\n",
        "Not distance based methods\n",
        "* Spectral clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzbvORzjYeAK"
      },
      "source": [
        "## K-means clustering \n",
        "k = 2 gives the best performance [20]. One cluster is labeled defective and one is labeled clean. \n",
        "\n",
        "## Short description\n",
        "K-mean is an unsupervised distance-based algorithm that looks for clusters in a dataset. It is initiated by determining “k” number of clusters. In our case, we will use two since we want a “defect” and “not defect” cluster. The algorithm randomly chooses k number of centroids in feature space. Centroids are simply a starting point in our space. The k-mean algorithm then assigns all data-points to the centroid they are located the closest to base on the Euclidian distance. Once all datapoints have been assigned to a cluster, the centroids of these clusters will be updated to the mean of the clusters. The model iterates this process until the centroids no longer changes. \n",
        "That is 1) reassigning datapoints to their closest centroid and 2) updating the centroid to be the middle of the data points. Once the centroids no longer move, the model terminates. \n",
        "\n",
        "As the number of features increase, any distance based algorithm's similarity measure will converge toward some constant. The so-called curse of dimensionality. This will translates into worse performance. K-means are therefore better suited for less features. On the other hand, k-means typically performs well, for less features that is, and do not have rigid assumptions about the data. It is thus a default ML technique to test when trying to classify variables. \n",
        "\n",
        "\n",
        "\n",
        "## Tuning parameters\n",
        "An issue with k-means is its sensitivity to the initial centroids. It does not guarantee the best solution but rather stops at a local equilibrium. For that reason, we choose to iterate the process many times to ensure that we do get a good prediction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0x_tPhTUYiGZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def KN(df_train):\n",
        "    y_train = list(df_train['class'])\n",
        "    scaled_train_X = scale_data_unsupervised(df_train)\n",
        "\n",
        "    kmeans = KMeans(n_clusters=2, n_init=200, random_state = 7, tol = 0.0001)\n",
        "    kmeans.fit(scaled_train_X)\n",
        "    y_pred = kmeans.predict(scaled_train_X)\n",
        "    return y_pred, y_train\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGs2ZZksShbS",
        "outputId": "6ac132c3-8077-4658-d718-5dea31337530"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "AUC score for Eclipse JDT Core, AEEEM_JDT   : 0.67\n",
            "\n",
            "AUC score for Equinox, AEEEM_EQ  : 0.56\n",
            "\n",
            "AUC score for Apache Lucene , AEEEM_LC  : 0.42\n",
            "\n",
            "AUC score for Mylyn, AEEEM_ML : 0.58\n",
            "\n",
            "AUC score for Eclipse PDE UI, AEEEM_PDE  : 0.62\n",
            "\n",
            "Mean AUC score for all projects: 0.57\n"
          ]
        }
      ],
      "source": [
        "get_auc_scores(project_dict_AEEEM, KN, AUC_unsupervised)\n",
        "\n",
        "#get_auc_scores(project_dict_NASA, KN, AUC_unsupervised)\n",
        "\n",
        "#get_auc_scores(project_dict_PROMISE, KN, AUC_unsupervised)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNow0yVyYye_"
      },
      "source": [
        "## Spectral clustering\n",
        "Spectral clustering partitions a data set based on the connectivity between its entities. \n",
        "\n",
        "Each node represents a  software entity (file or class)\n",
        "Each edge represents the connection between software entities, and its weight is measured by the similarity of metric values between its two ends. \n",
        "\n",
        "similarity:\n",
        "$$\n",
        "w_{i,j} = \\textbf{x}_{i} ⋅ \\textbf{x}_{j} = \\sum_{k=1}^{m} a_{i,k} a_{k,j}\n",
        ",$$\n",
        "$x_i$ and $x_j$ denote the metric values of software entities $i$ and $j$, respectively,\n",
        "\n",
        "$a_{k,j}$ is the value of the $k$-th metric on the $j$-th software entity and m is the total number of metrics. \n",
        "\n",
        "## Short description\n",
        "\n",
        "*   unsupervised / supervised\n",
        "*   hierarchical method or .... \n",
        "*   typically good for, when is it used, why have we  included it\n",
        "\n",
        "\n",
        "\n",
        "## Tuning parameters\n",
        "short discussion\n",
        "\n",
        "justify the ones we ended up with \n",
        "\n",
        "## Math / pseudocode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUjb3hcNsime"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import SpectralClustering\n",
        "\n",
        "def adjacency_matrix(df):\n",
        "    # Normalize software metrices unsing z-score \n",
        "    y = np.zeros(np.shape(df)[0])\n",
        "    #y = list(df[\"class\"])\n",
        "    n = len(y)\n",
        "    scaled_X = scale_data_unsupervised(df)\n",
        "    \n",
        "    # Construct a weighted adjacency matrix W\n",
        "    W = np.zeros((n, n))\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            if j != i:\n",
        "                W[i,j] = np.dot(scaled_X.iloc[i, :], scaled_X.iloc[j, :])\n",
        "    W = W.clip(min=0)\n",
        "    return W\n",
        "\n",
        "def spectral_clustering(df, df_test=0):\n",
        "    y = list(df[\"class\"])\n",
        "    scaled_X = scale_data_unsupervised(df)\n",
        "    W = adjacency_matrix(df)\n",
        "    clustering = SpectralClustering(n_clusters=2, affinity = 'precomputed', random_state = 2, n_jobs = -1)\n",
        "    clustering.fit(W)   \n",
        "    y_pred = clustering.labels_\n",
        "    return y_pred, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "GS-ZnrJT1gq1",
        "outputId": "e269c7e3-67c6-4562-cf0c-c0c9ba282a82"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-08d908ffd767>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_auc_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_dict_AEEEM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspectral_clustering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAUC_unsupervised\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#get_auc_scores(project_dict_NASA, spectral_clustering, AUC_unsupervised)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#get_auc_scores(project_dict_PROMISE, spectral_clustering, AUC_unsupervised)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-70063e259151>\u001b[0m in \u001b[0;36mget_auc_scores\u001b[0;34m(project_dict, func, auc_func)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mtest_project\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproject_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_project\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_project\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nAUC score for '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mproject_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' :'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0maverage_auc_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-70063e259151>\u001b[0m in \u001b[0;36mAUC_unsupervised\u001b[0;34m(function, df, project_list)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mAUC_unsupervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-c224a37ba07f>\u001b[0m in \u001b[0;36mspectral_clustering\u001b[0;34m(df, df_test)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mscaled_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_data_unsupervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madjacency_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mclustering\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpectralClustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffinity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'precomputed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mclustering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-c224a37ba07f>\u001b[0m in \u001b[0;36madjacency_matrix\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    871\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1445\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1446\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    784\u001b[0m                 \u001b[0;31m# We don't need to check for tuples here because those are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0;31m#  caught by the _is_nested_tuple_indexer check above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m                 \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0;31m# We should never have a scalar section here, because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   2835\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2836\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2837\u001b[0;31m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2838\u001b[0m             )\n\u001b[1;32m   2839\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mfrom_array\u001b[0;34m(cls, array, index)\u001b[0m\n\u001b[1;32m   1576\u001b[0m         \u001b[0mConstructor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0myet\u001b[0m \u001b[0ma\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1577\u001b[0m         \"\"\"\n\u001b[0;32m-> 1578\u001b[0;31m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1579\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   2735\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2736\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2737\u001b[0;31m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_block_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2739\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mDatetimeTZBlock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mget_block_type\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m   2701\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatetimeTZBlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mis_interval_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_period_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mObjectValuesExtensionBlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_interval_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr_or_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mIntervalDtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/dtypes.py\u001b[0m in \u001b[0;36mis_dtype\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m   1134\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     def __from_arrow__(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/base.py\u001b[0m in \u001b[0;36mis_dtype\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m             \u001b[0;31m# https://github.com/pandas-dev/pandas/issues/22960\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;31m# avoid passing data to `construct_from_string`. This could\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/generic.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_typ\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__instancecheck__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "get_auc_scores(project_dict_AEEEM, spectral_clustering, AUC_unsupervised)\n",
        "\n",
        "#get_auc_scores(project_dict_NASA, spectral_clustering, AUC_unsupervised)\n",
        "\n",
        "#get_auc_scores(project_dict_PROMISE, spectral_clustering, AUC_unsupervised)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3ZygGBuLNep"
      },
      "source": [
        "# Performance\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rwh-XtF4Rlzs"
      },
      "source": [
        "## AUC\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGi6iF6iRnGu"
      },
      "source": [
        "## Scott Knot test\n",
        "To compare the predictive power among all classifiers, we apply the Scott-Knott test with the 95% confidence level to rank all classifiers across projects within the same dataset. We examine the Scott-Knott ranks per dataset. Furthermore, we perform one large Scott-Knott run where we input all the AUC values for all the classifiers across all datasets. \n",
        "\n",
        "(this is copied from the rapport and must be rewritten if we are going to use it in our priject)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtERMHQRjXP6"
      },
      "source": [
        "# Discussion "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U38LpBOvjawm"
      },
      "source": [
        "# Future suggestions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbRV3Vn2-iCB"
      },
      "source": [
        "# APPENDIX 1 - DATA TABLE NAMES\n",
        "| Metric                            | Description                                                  |\n",
        "| --------------------------------- | ------------------------------------------------------------ |\n",
        "| classname                         | Name of the class                                            |\n",
        "| numberOfVersionsUntil. (NR)       | Number of versions (revisions) before last release           |\n",
        "| numberOfFixesUntil. (NFIX)        | Number of fixes before last release                          |\n",
        "| numberOfRefactoringsUntil. (NREF) | Number of refactorings before last release                   |\n",
        "| numberOfAuthorsUntil. (NAUTH)     | Number of authors before last release                        |\n",
        "| linesAddedUntil.                  | Sum of all the lines added between all the revisions (before last release) |\n",
        "| maxLinesAddedUntil.               | Maximum number of lines added in a single revision           |\n",
        "| avgLinesAddedUntil.               | Average number of lines added in a single revision           |\n",
        "| linesRemovedUntil.                | Sum of all the lines removed between all the revisions (before last release) |\n",
        "| maxLinesRemovedUntil.             | Maximum number of lines removed in a single revision         |\n",
        "| avgLinesRemovedUntil.             | Average number of lines removed in a single revision         |\n",
        "| codeChurnUntil.                   | How many times the class has been edited between all the revisions before last release |\n",
        "| maxCodeChurnUntil.                | Maximum number of times the class has been edited in a single revision |\n",
        "| avgCodeChurnUntil.                | Average number of times the class has been edited in a single revision |\n",
        "| ageWithRespectTo.                 | Age of the class                                             |\n",
        "| weightedAgeWithRespectTo.         | Weighted age of the class                                    |\n",
        "| bugs                              | Number of bugs found after last release                      |\n",
        "| nonTrivialBugs                    | Number of non trivial bugs found after last release          |\n",
        "| majorBugs                         | Number of major bugs found after last release                |\n",
        "| criticalBugs                      | Number of critical bugs found after last release             |\n",
        "| highPriorityBugs                  | Number of high priority bugs found after last release        |\n",
        "\n",
        "\n",
        "| Metric                 | Description                                                  |\n",
        "| ---------------------- | ------------------------------------------------------------ |\n",
        "| classname              | Name of the class                                            |\n",
        "| CvsEntropy (HCM)       | History of complexity metric                                 |\n",
        "| CvsWEntropy (WHCM)     | Weighted history of complexity metric                        |\n",
        "| CvsLinEntropy (LDHCM)  | Linearly decayed history of complexity metric (the contributions given by every change decay linearly) |\n",
        "| CvsLogEntropy (LGDHCM) | Logarithmically decayed history of complexity metric (the contributions given by every change decay logarithmically) |\n",
        "| CvsExpEntropy (EDHCM)  | Exponentially decayed history of complexity metric (the contributions given by every change decay exponentially) |\n",
        "\n",
        "\n",
        "| Metric                              | Description                                            |\n",
        "| ----------------------------------- | ------------------------------------------------------ |\n",
        "| classname                           | Name of the class                                      |\n",
        "| numberOfBugsFoundUntil.             | Number of bugs found before last release               |\n",
        "| numberOfNonTrivialBugsFoundUntil.   | Number of non trivial bugs found before last release   |\n",
        "| numberOfMajorBugsFoundUntil.        | Number of major bugs found before last release         |\n",
        "| numberOfCriticalBugsFoundUntil.     | Number of critical bugs found before last release      |\n",
        "| numberOfHighPriorityBugsFoundUntil. | Number of high priority bugs found before last release |\n",
        "| bugs                                | Number of bugs found after last release                |\n",
        "| nonTrivialBugs                      | Number of non trivial bugs found after last release    |\n",
        "| majorBugs                           | Number of major bugs found after last release          |\n",
        "| criticalBugs                        | Number of critical bugs found after last release       |\n",
        "| highPriorityBugs                    | Number of high priority bugs found after last release  |\n",
        "\n",
        "* Contains all the CK (from the Chidamber and Kemerer suite) and OO (object-oriented) metrics.\n",
        "\n",
        "| Metric                             | Description                                             |\n",
        "| ---------------------------------- | ------------------------------------------------------- |\n",
        "| classname                          | Name of the class                                       |\n",
        "| cbo                                | Coupling between objects (CK)                           |\n",
        "| dit                                | Depth of inheritance tree (CK)                          |\n",
        "| fanIn                              | Number of classes that reference the class (OO)         |\n",
        "| fanOut                             | Number of classes that are referenced by the class (OO) |\n",
        "| lcom                               | Lack of cohesion in methods (CK)                        |\n",
        "| noc                                | Number of children (CK)                                 |\n",
        "| numberOfAttributes (NOA)           | Number of attributes in the class (OO)                  |\n",
        "| numberOfAttributesInherited (NOAI) | Number of attributes inherited by the class (OO)        |\n",
        "| numberOfLinesOfCode (LOC)          | Lines of code (OO)                                      |\n",
        "| numberOfMethods (NOM)              | Number of methods in the class (OO)                     |\n",
        "| numberOfMethodsInherited (NOMI)    | Number of methods inherited by the class (OO)           |\n",
        "| numberOfPrivateAttributes (NOPRA)  | Number of private attributes in the class (OO)          |\n",
        "| numberOfPrivateMethods (NOPRM)     | Number of private methods in the class (OO)             |\n",
        "| numberOfPublicAttributes (NOPA)    | Number of public attributes in the class (OO)           |\n",
        "| numberOfPublicMethods (NOPM)       | Number of public methods in the class (OO)              |\n",
        "| rfc                                | Response for class (CK)                                 |\n",
        "| wmc                                | Weighted method count (CK)                              |\n",
        "| bugs                               | Number of bugs found after last release                 |\n",
        "| nonTrivialBugs                     | Number of non trivial bugs found after last release     |\n",
        "| majorBugs                          | Number of major bugs found after last release           |\n",
        "| criticalBugs                       | Number of critical bugs found after last release        |\n",
        "| highPriorityBugs                   | Number of high priority bugs found after last release   |\n",
        "\n",
        "* Contains the entropy calculated for every CK and OO metric.\n",
        "\n",
        "| Metric                      | Description                                           |\n",
        "| --------------------------- | ----------------------------------------------------- |\n",
        "| cbo                         | Entropy for cbo                                       |\n",
        "| dit                         | Entropy for dit                                       |\n",
        "| fanIn                       | Entropy for fanIn                                     |\n",
        "| fanOut                      | Entropy for fanOut                                    |\n",
        "| lcom                        | Entropy for lcom                                      |\n",
        "| noc                         | Entropy for noc                                       |\n",
        "| numberOfAttributes          | Entropy for numberOfAttributes                        |\n",
        "| numberOfAttributesInherited | Entropy for numberOfAttributesInherited               |\n",
        "| numberOfLinesOfCode         | Entropy for numberOfLinesOfCode                       |\n",
        "| numberOfMethods             | Entropy for numberOfMethods                           |\n",
        "| numberOfMethodsInherited    | Entropy for numberOfMethodsInherited                  |\n",
        "| numberOfPrivateAttributes   | Entropy for numberOfPrivateAttributes                 |\n",
        "| numberOfPrivateMethods      | Entropy for numberOfPrivateMethods                    |\n",
        "| numberOfPublicAttributes    | Entropy for numberOfPublicAttributes                  |\n",
        "| numberOfPublicMethods       | Entropy for numberOfPublicMethods                     |\n",
        "| rfc                         | Entropy for rfc                                       |\n",
        "| wmc                         | Entropy for wmc                                       |\n",
        "| bugs                        | Number of bugs found after last release               |\n",
        "| nonTrivialBugs              | Number of non trivial bugs found after last release   |\n",
        "| majorBugs                   | Number of major bugs found after last release         |\n",
        "| criticalBugs                | Number of critical bugs found after last release      |\n",
        "| highPriorityBugs            | Number of high priority bugs found after last release |\n",
        "\n",
        "* Contains the code churn calculated for every CK and OO metric. The code churn measures how frequently the metrics have changed in time. Classes with very high code churn for many metrics will have more bugs.\n",
        "\n",
        "| Metric                      | Description                                           |\n",
        "| --------------------------- | ----------------------------------------------------- |\n",
        "| cbo                         | Code churn cbo                                        |\n",
        "| dit                         | Code churn dit                                        |\n",
        "| fanIn                       | Code churn fanIn                                      |\n",
        "| fanOut                      | Code churn fanOut                                     |\n",
        "| lcom                        | Code churn lcom                                       |\n",
        "| noc                         | Code churn noc                                        |\n",
        "| numberOfAttributes          | Code churn numberOfAttributes                         |\n",
        "| numberOfAttributesInherited | Code churn numberOfAttributesInherited                |\n",
        "| numberOfLinesOfCode         | Code churn numberOfLinesOfCode                        |\n",
        "| numberOfMethods             | Code churn numberOfMethods                            |\n",
        "| numberOfMethodsInherited    | Code churn numberOfMethodsInherited                   |\n",
        "| numberOfPrivateAttributes   | Code churn numberOfPrivateAttributes                  |\n",
        "| numberOfPrivateMethods      | Code churn numberOfPrivateMethods                     |\n",
        "| numberOfPublicAttributes    | Code churn numberOfPublicAttributes                   |\n",
        "| numberOfPublicMethods       | Code churn numberOfPublicMethods                      |\n",
        "| rfc                         | Code churn rfc                                        |\n",
        "| wmc                         | Code churn wmc                                        |\n",
        "| bugs                        | Number of bugs found after last release               |\n",
        "| nonTrivialBugs              | Number of non trivial bugs found after last release   |\n",
        "| majorBugs                   | Number of major bugs found after last release         |\n",
        "| criticalBugs                | Number of critical bugs found after last release      |\n",
        "| highPriorityBugs            | Number of high priority bugs found after last release |\n",
        "\n",
        "NB: to access the tables containing transformations of these code churn values, it is necessary to add the transformation option (which can be exp, lin, log, weighted).\n",
        "\n",
        "* Contains data about how each CK metric changes over time, for every class. \n",
        "\n",
        "| Time      | Description                                                  |\n",
        "| --------- | ------------------------------------------------------------ |\n",
        "| classname | Name of the class                                            |\n",
        "| Time 1    | First value recorded of the selected metric                  |\n",
        "| Time 2    | Second value recorded of the selected metric (recorded after two weeks from the first) |\n",
        "| ...       | ...                                                          |\n",
        "| Time 50   | Last value recorded of the selected metric (2 years and 1 month after the first value recorded) |\n",
        "\n",
        "NB: when the value of the metric hasn't changed between one time and the other, its value is set to -1.\n",
        "\n",
        "* Contains complexity metrics and values for the abstract syntax tree nodes at the file level.\n",
        "\n",
        "Note: FOUT_sum is the same as fanOut \n",
        "\n",
        "| Complexity Metrics | Description                            |\n",
        "| ------------------ | -------------------------------------- |\n",
        "| plugin             | Name of the plugin                     |\n",
        "| filename           | Name of the file                       |\n",
        "| pre                | Pre release number of defects          |\n",
        "| post               | Post release number of defects         |\n",
        "| ACD                | Number of anonymous type declarations  |\n",
        "| FOUT_avg           | Average number of method calls         |\n",
        "| FOUT_max           | Maximum number of method calls         |\n",
        "| FOUT_sum           | Sum of all method calls                |\n",
        "| MLOC_avg           | Method lines of code                   |\n",
        "| MLOC_max           | Maximum method lines of code           |\n",
        "| MLOC_sum           | Sum of all method lines of code        |\n",
        "| NBD_avg            | Average nested block depth             |\n",
        "| NBD_max            | Maximum nested block depth             |\n",
        "| NBD_sum            | Sum of nested block depth              |\n",
        "| NOF_avg            | Average number of fields               |\n",
        "| NOF_max            | Maximum number of fields               |\n",
        "| NOF_sum            | Sum of number of fields                |\n",
        "| NOI_avg            | Average number of interfaces           |\n",
        "| NOI_max            | Maximum number of interfaces           |\n",
        "| NOI_sum            | Sum of number of interfaces            |\n",
        "| NOM_avg            | Average number of methods              |\n",
        "| NOM_max            | Maximum number of methods              |\n",
        "| NOM_sum            | Sum of number of methods               |\n",
        "| NOT                | Number of classes                      |\n",
        "| NSF_avg            | Average number of static fields        |\n",
        "| NSF_max            | Maximum number of static fields        |\n",
        "| NSF_sum            | Sum of number of static fields         |\n",
        "| NSM_avg            | Average number of static methods       |\n",
        "| NSM_max            | Maximum number of static methods       |\n",
        "| NSM_sum            | Sum of number of static methods        |\n",
        "| PAR_avg            | Average number of parameters           |\n",
        "| PAR_max            | Maximum number of parameters           |\n",
        "| PAR_sum            | Sum of number of parameters            |\n",
        "| TLOC               | Total lines of code                    |\n",
        "| VG_avg             | Average McCabe's cyclomatic complexity |\n",
        "| VG_max             | Maximum McCabe's cyclomatic complexity |\n",
        "| VG_sum             | Sum of McCabe's cyclomatic complexity  |\n",
        "\n",
        "* Contains complexity metrics and values for the abstract syntax tree nodes at the package level.\n",
        "\n",
        "In this type of table the average, maximum and sum of ACD, NOT and TLOC have been computed (not the single values). Also the variable NOCU has been added (number of files for every package).\n",
        "\n",
        "| Complexity Metrics | Description                                   |\n",
        "| ------------------ | --------------------------------------------- |\n",
        "| plugin             | Name of the plugin                            |\n",
        "| packagename        | Name of the package                           |\n",
        "| pre                | Pre release number of defects                 |\n",
        "| post               | Post release number of defects                |\n",
        "| ACD_avg            | Average number of anonymous type declarations |\n",
        "| ACD_max            | Maximum number of anonymous type declarations |\n",
        "| ACD_sum            | Sum of number of anonymous type declarations  |\n",
        "| FOUT_avg           | Average number of method calls                |\n",
        "| FOUT_max           | Maximum number of method calls                |\n",
        "| FOUT_sum           | Sum of all method calls                       |\n",
        "| MLOC_avg           | Method lines of code                          |\n",
        "| MLOC_max           | Maximum method lines of code                  |\n",
        "| MLOC_sum           | Sum of all method lines of code               |\n",
        "| NBD_avg            | Average nested block depth                    |\n",
        "| NBD_max            | Maximum nested block depth                    |\n",
        "| NBD_sum            | Sum of nested block depth                     |\n",
        "| NOCU               | Number of compilation units (files)           |\n",
        "| NOF_avg            | Average number of fields                      |\n",
        "| NOF_max            | Maximum number of fields                      |\n",
        "| NOF_sum            | Sum of number of fields                       |\n",
        "| NOI_avg            | Average number of interfaces                  |\n",
        "| NOI_max            | Maximum number of interfaces                  |\n",
        "| NOI_sum            | Sum of number of interfaces                   |\n",
        "| NOM_avg            | Average number of methods                     |\n",
        "| NOM_max            | Maximum number of methods                     |\n",
        "| NOM_sum            | Sum of number of methods                      |\n",
        "| NOT_avg            | Average number of classes                     |\n",
        "| NOT_max            | Maximum number of classes                     |\n",
        "| NOT_sum            | Sum of number of classes                      |\n",
        "| NSF_avg            | Average number of static fields               |\n",
        "| NSF_max            | Maximum number of static fields               |\n",
        "| NSF_sum            | Sum of number of static fields                |\n",
        "| NSM_avg            | Average number of static methods              |\n",
        "| NSM_max            | Maximum number of static methods              |\n",
        "| NSM_sum            | Sum of number of static methods               |\n",
        "| PAR_avg            | Average number of parameters                  |\n",
        "| PAR_max            | Maximum number of parameters                  |\n",
        "| PAR_sum            | Sum of number of parameters                   |\n",
        "| TLOC_avg           | Average number of total lines of code         |\n",
        "| TLOC_max           | Maximum number of total lines of code         |\n",
        "| TLOC_sum           | Sum of number of total lines of code          |\n",
        "| VG_avg             | Average McCabe's cyclomatic complexity        |\n",
        "| VG_max             | Maximum McCabe's cyclomatic complexity        |\n",
        "| VG_sum             | Sum of McCabe's cyclomatic complexity         |\n",
        "\n",
        "* Contains burst metrics at hourly time intervals. \n",
        "\n",
        "| Metric                          | Description                                                  |\n",
        "| ------------------------------- | ------------------------------------------------------------ |\n",
        "| filename                        | Name of the class                                            |\n",
        "| TotalPeopleInBurst              | Number of people involved across all bursts                  |\n",
        "| MaximumCodeBurstLate            | Maximum late code bursts                                     |\n",
        "| NumberOfChanges                 | Number of builds in which the component has changed          |\n",
        "| MaxPeopleInBurst                | Across all bursts, maximum number of people involved         |\n",
        "| TotalBurstSizeLate              | Total size of late bursts                                    |\n",
        "| NumberCodeBurstsLate            | Number of late code bursts                                   |\n",
        "| NumberOfChangesLate             | Number of late builds in which the component has changed     |\n",
        "| NumberOfChangesEarly            | Number of early builds in which the component has changed    |\n",
        "| MaxChurnInBurst                 | Maximum code churn across all bursts                         |\n",
        "| MaximumCodeBurstEarly           | Maximum number of early code bursts                          |\n",
        "| NumberCodeBurstsEarly           | Number of early code bursts                                  |\n",
        "| TimeFirstBurst                  | Time when the first burst occurred                           |\n",
        "| TotalChurnInBurst               | Total code churn in all change bursts                        |\n",
        "| ChurnTotal                      | Total code churn during the lifetime of a component          |\n",
        "| MaximumCodeBurst                | Maximum number of code bursts                                |\n",
        "| NumberOfConsecutiveChangesEarly | Number of early consecutive builds (takes into account all consecutive changes, not just bursts exceeding a certain size) |\n",
        "| NumberConsecutiveChangesLate    | Number of late consecutive builds (takes into account all consecutive changes, not just bursts exceeding a certain size) |\n",
        "| TotalBurstSizeEarly             | Total size of early bursts                                   |\n",
        "| TotalBurstSize                  | Total size of all bursts                                     |\n",
        "| TimeMaxBurst                    | Time when the maximum burst occurred                         |\n",
        "| NumberOfConsecutiveChanges      | Number of consecutive changes (takes into account all consecutive changes, not just bursts exceeding a certain size) |\n",
        "| TimeLastBurst                   | Time when the last burst occurred                            |\n",
        "| NumberCodeBursts                | Number of code bursts                                        |\n",
        "| PeopleTotal                     | Number of people who ever committed a change to the component |\n",
        "\n",
        "At hourly time intervals we don't have a column with the number of bugs, so this data will be suited for unsupervised learning.\n",
        "\n",
        "Contains burst metrics at daily time intervals, at the class level.\n",
        "\n",
        "| Metric                          | Description                                                  |\n",
        "| ------------------------------- | ------------------------------------------------------------ |\n",
        "| filename                        | Name of the class                                            |\n",
        "| TotalPeopleInBurst              | Number of people involved across all bursts                  |\n",
        "| MaximumCodeBurstLate            | Maximum late code bursts                                     |\n",
        "| NumberOfChanges                 | Number of builds in which the component has changed          |\n",
        "| MaxPeopleInBurst                | Across all bursts, maximum number of people involved         |\n",
        "| TotalBurstSizeLate              | Total size of late bursts                                    |\n",
        "| NumberCodeBurstsLate            | Number of late code bursts                                   |\n",
        "| NumberOfChangesLate             | Number of late builds in which the component has changed     |\n",
        "| NumberOfChangesEarly            | Number of early builds in which the component has changed    |\n",
        "| MaxChurnInBurst                 | Maximum code churn across all bursts                         |\n",
        "| MaximumCodeBurstEarly           | Maximum number of early code bursts                          |\n",
        "| NumberCodeBurstsEarly           | Number of early code bursts                                  |\n",
        "| TimeFirstBurst                  | Time when the first burst occurred                           |\n",
        "| TotalChurnInBurst               | Total code churn in all change bursts                        |\n",
        "| ChurnTotal                      | Total code churn during the lifetime of a component          |\n",
        "| MaximumCodeBurst                | Maximum number of code bursts                                |\n",
        "| NumberOfConsecutiveChangesEarly | Number of early consecutive builds (takes into account all consecutive changes, not just bursts exceeding a certain size) |\n",
        "| NumberConsecutiveChangesLate    | Number of late consecutive builds (takes into account all consecutive changes, not just bursts exceeding a certain size) |\n",
        "| TotalBurstSizeEarly             | Total size of early bursts                                   |\n",
        "| TotalBurstSize                  | Total size of all bursts                                     |\n",
        "| TimeMaxBurst                    | Time when the maximum burst occurred                         |\n",
        "| NumberOfConsecutiveChanges      | Number of consecutive changes (takes into account all consecutive changes, not just bursts exceeding a certain size) |\n",
        "| TimeLastBurst                   | Time when the last burst occurred                            |\n",
        "| NumberCodeBursts                | Number of code bursts                                        |\n",
        "| PeopleTotal                     | Number of people who ever committed a change to the component |\n",
        "| bugs                            | Number of bugs                                               |\n",
        "\n",
        "* Contains burst metrics at daily time intervals, at the package level. Also contains the same package metrics as the type ecl_package_Version from the above datasets.\n",
        "\n",
        "| Metric                          | Description                                                  |\n",
        "| ------------------------------- | ------------------------------------------------------------ |\n",
        "| filename                        | Name of the package                                          |\n",
        "| TotalPeopleInBurst              | Number of people involved across all bursts                  |\n",
        "| MaximumCodeBurstLate            | Maximum late code bursts                                     |\n",
        "| NumberOfChanges                 | Number of builds in which the component has changed          |\n",
        "| MaxPeopleInBurst                | Across all bursts, maximum number of people involved         |\n",
        "| TotalBurstSizeLate              | Total size of late bursts                                    |\n",
        "| NumberCodeBurstsLate            | Number of late code bursts                                   |\n",
        "| NumberOfChangesLate             | Number of late builds in which the component has changed     |\n",
        "| NumberOfChangesEarly            | Number of early builds in which the component has changed    |\n",
        "| MaxChurnInBurst                 | Maximum code churn across all bursts                         |\n",
        "| MaximumCodeBurstEarly           | Maximum number of early code bursts                          |\n",
        "| NumberCodeBurstsEarly           | Number of early code bursts                                  |\n",
        "| TimeFirstBurst                  | Time when the first burst occurred                           |\n",
        "| TotalChurnInBurst               | Total code churn in all change bursts                        |\n",
        "| ChurnTotal                      | Total code churn during the lifetime of a component          |\n",
        "| MaximumCodeBurst                | Maximum number of code bursts                                |\n",
        "| NumberOfConsecutiveChangesEarly | Number of early consecutive builds (takes into account all consecutive changes, not just bursts exceeding a certain size) |\n",
        "| NumberConsecutiveChangesLate    | Number of late consecutive builds (takes into account all consecutive changes, not just bursts exceeding a certain size) |\n",
        "| TotalBurstSizeEarly             | Total size of early bursts                                   |\n",
        "| TotalBurstSize                  | Total size of all bursts                                     |\n",
        "| TimeMaxBurst                    | Time when the maximum burst occurred                         |\n",
        "| NumberOfConsecutiveChanges      | Number of consecutive changes (takes into account all consecutive changes, not just bursts exceeding a certain size) |\n",
        "| TimeLastBurst                   | Time when the last burst occurred                            |\n",
        "| NumberCodeBursts                | Number of code bursts                                        |\n",
        "| PeopleTotal                     | Number of people who ever committed a change to the component |\n",
        "| pre                             | Pre release number of defects                                |\n",
        "| NumberOfDefects                 | Post release number of defects (equal to \"post\" from above)  |\n",
        "| ACD_avg                         | Average number of anonymous type declarations                |\n",
        "| ACD_max                         | Maximum number of anonymous type declarations                |\n",
        "| ACD_sum                         | Sum of number of anonymous type declarations                 |\n",
        "| FOUT_avg                        | Average number of method calls                               |\n",
        "| FOUT_max                        | Maximum number of method calls                               |\n",
        "| FOUT_sum                        | Sum of all method calls                                      |\n",
        "| MLOC_avg                        | Method lines of code                                         |\n",
        "| MLOC_max                        | Maximum method lines of code                                 |\n",
        "| MLOC_sum                        | Sum of all method lines of code                              |\n",
        "| NBD_avg                         | Average nested block depth                                   |\n",
        "| NBD_max                         | Maximum nested block depth                                   |\n",
        "| NBD_sum                         | Sum of nested block depth                                    |\n",
        "| NOCU                            | Number of compilation units (files)                          |\n",
        "| NOF_avg                         | Average number of fields                                     |\n",
        "| NOF_max                         | Maximum number of fields                                     |\n",
        "| NOF_sum                         | Sum of number of fields                                      |\n",
        "| NOI_avg                         | Average number of interfaces                                 |\n",
        "| NOI_max                         | Maximum number of interfaces                                 |\n",
        "| NOI_sum                         | Sum of number of interfaces                                  |\n",
        "| NOM_avg                         | Average number of methods                                    |\n",
        "| NOM_max                         | Maximum number of methods                                    |\n",
        "| NOM_sum                         | Sum of number of methods                                     |\n",
        "| NOT_avg                         | Average number of classes                                    |\n",
        "| NOT_max                         | Maximum number of classes                                    |\n",
        "| NOT_sum                         | Sum of number of classes                                     |\n",
        "| NSF_avg                         | Average number of static fields                              |\n",
        "| NSF_max                         | Maximum number of static fields                              |\n",
        "| NSF_sum                         | Sum of number of static fields                               |\n",
        "| NSM_avg                         | Average number of static methods                             |\n",
        "| NSM_max                         | Maximum number of static methods                             |\n",
        "| NSM_sum                         | Sum of number of static methods                              |\n",
        "| PAR_avg                         | Average number of parameters                                 |\n",
        "| PAR_max                         | Maximum number of parameters                                 |\n",
        "| PAR_sum                         | Sum of number of parameters                                  |\n",
        "| TLOC_avg                        | Average number of total lines of code                        |\n",
        "| TLOC_max                        | Maximum number of total lines of code                        |\n",
        "| TLOC_sum                        | Sum of number of total lines of code                         |\n",
        "| VG_avg                          | Average McCabe's cyclomatic complexity                       |\n",
        "| VG_max                          | Maximum McCabe's cyclomatic complexity                       |\n",
        "| VG_sum                          | Sum of McCabe's cyclomatic complexity                        |\n",
        "\n",
        "Contains burst metrics at weekly time intervals, at the class level. Also contains the same class metrics as the type ecl_file_Version from the above datasets.\n",
        "\n",
        "| Metric                          | Description                                                  |\n",
        "| ------------------------------- | ------------------------------------------------------------ |\n",
        "| filename                        | Name of the class                                            |\n",
        "| TotalPeopleInBurst              | Number of people involved across all bursts                  |\n",
        "| MaximumCodeBurstLate            | Maximum late code bursts                                     |\n",
        "| NumberOfChanges                 | Number of builds in which the component has changed          |\n",
        "| MaxPeopleInBurst                | Across all bursts, maximum number of people involved         |\n",
        "| TotalBurstSizeLate              | Total size of late bursts                                    |\n",
        "| NumberCodeBurstsLate            | Number of late code bursts                                   |\n",
        "| NumberOfChangesLate             | Number of late builds in which the component has changed     |\n",
        "| NumberOfChangesEarly            | Number of early builds in which the component has changed    |\n",
        "| MaxChurnInBurst                 | Maximum code churn across all bursts                         |\n",
        "| MaximumCodeBurstEarly           | Maximum number of early code bursts                          |\n",
        "| NumberCodeBurstsEarly           | Number of early code bursts                                  |\n",
        "| TimeFirstBurst                  | Time when the first burst occurred                           |\n",
        "| TotalChurnInBurst               | Total code churn in all change bursts                        |\n",
        "| ChurnTotal                      | Total code churn during the lifetime of a component          |\n",
        "| MaximumCodeBurst                | Maximum number of code bursts                                |\n",
        "| NumberOfConsecutiveChangesEarly | Number of early consecutive builds (takes into account all consecutive changes, not just bursts exceeding a certain size) |\n",
        "| NumberConsecutiveChangesLate    | Number of late consecutive builds (takes into account all consecutive changes, not just bursts exceeding a certain size) |\n",
        "| TotalBurstSizeEarly             | Total size of early bursts                                   |\n",
        "| TotalBurstSize                  | Total size of all bursts                                     |\n",
        "| TimeMaxBurst                    | Time when the maximum burst occurred                         |\n",
        "| NumberOfConsecutiveChanges      | Number of consecutive changes (takes into account all consecutive changes, not just bursts exceeding a certain size) |\n",
        "| TimeLastBurst                   | Time when the last burst occurred                            |\n",
        "| NumberCodeBursts                | Number of code bursts                                        |\n",
        "| PeopleTotal                     | Number of people who ever committed a change to the component |\n",
        "| pre                             | Pre release number of defects                                |\n",
        "| NumberOfDefects                 | Post release number of defects (equal to \"post\" from above)  |\n",
        "| ACD                             | Number of anonymous type declarations                        |\n",
        "| FOUT_avg                        | Average number of method calls                               |\n",
        "| FOUT_max                        | Maximum number of method calls                               |\n",
        "| FOUT_sum                        | Sum of all method calls                                      |\n",
        "| MLOC_avg                        | Method lines of code                                         |\n",
        "| MLOC_max                        | Maximum method lines of code                                 |\n",
        "| MLOC_sum                        | Sum of all method lines of code                              |\n",
        "| NBD_avg                         | Average nested block depth                                   |\n",
        "| NBD_max                         | Maximum nested block depth                                   |\n",
        "| NBD_sum                         | Sum of nested block depth                                    |\n",
        "| NOF_avg                         | Average number of fields                                     |\n",
        "| NOF_max                         | Maximum number of fields                                     |\n",
        "| NOF_sum                         | Sum of number of fields                                      |\n",
        "| NOI_avg                         | Average number of interfaces                                 |\n",
        "| NOI_max                         | Maximum number of interfaces                                 |\n",
        "| NOI_sum                         | Sum of number of interfaces                                  |\n",
        "| NOM_avg                         | Average number of methods                                    |\n",
        "| NOM_max                         | Maximum number of methods                                    |\n",
        "| NOM_sum                         | Sum of number of methods                                     |\n",
        "| NOT                             | Number of classes                                            |\n",
        "| NSF_avg                         | Average number of static fields                              |\n",
        "| NSF_max                         | Maximum number of static fields                              |\n",
        "| NSF_sum                         | Sum of number of static fields                               |\n",
        "| NSM_avg                         | Average number of static methods                             |\n",
        "| NSM_max                         | Maximum number of static methods                             |\n",
        "| NSM_sum                         | Sum of number of static methods                              |\n",
        "| PAR_avg                         | Average number of parameters                                 |\n",
        "| PAR_max                         | Maximum number of parameters                                 |\n",
        "| PAR_sum                         | Sum of number of parameters                                  |\n",
        "| TLOC                            | Total lines of code                                          |\n",
        "| VG_avg                          | Average McCabe's cyclomatic complexity                       |\n",
        "| VG_max                          | Maximum McCabe's cyclomatic complexity                       |\n",
        "| VG_sum                          | Sum of McCabe's cyclomatic complexity                        |\n",
        "\n",
        "\n",
        "| Metric                           | Description                                                  |\n",
        "| -------------------------------- | ------------------------------------------------------------ |\n",
        "| LOC_BLANK                        | Number of blank lines of code                                |\n",
        "| BRANCH_COUNT                     | Number of logical branches                                   |\n",
        "| CALL_PAIRS                       | Executable calls between modules                             |\n",
        "| LOC_CODE_AND_COMMENT             | Lines of code + lines of comment                             |\n",
        "| LOC_COMMENTS                     | Lines of comment                                             |\n",
        "| CONDITION_COUNT                  | Number of conditions                                         |\n",
        "| CYCLOMATIC_COMPLEXITY            | McCabe's cyclomatic complexity (maximum number of linearly independent paths through a program's source code, computed from the control-flow graph). It's the number of conditional branches in the control-flow graph. M = E - N + 2P (E number of edges, N number of nodes, P number of connected components). Also called v(G). |\n",
        "| CYCLOMATIC_DENSITY               | Cyclomatic complexity divided by the size of the system (in source statements) |\n",
        "| DECISION_COUNT                   | Number of decisions                                          |\n",
        "| DECISION_DENSITY                 | Number of decisions divided by the size of the system        |\n",
        "| DESIGN_COMPLEXITY                | Number of paths which call something                         |\n",
        "| DESIGN_DENSITY                   | Design complexity divided by cyclomatic complexity (total paths) |\n",
        "| EDGE_COUNT                       | Number of edges of the control-flow graph                    |\n",
        "| ESSENTIAL_COMPLEXITY             | ESSCOM = (NONREDUC+1) + (ENTRYPT-1) + (TERMPT-1) Essential complexity is the sum of nonreducible nodes plus one, plus one for each entry point after the first, plus one for each termination point after the first. It's basically the complexity of the reduced flowgraph (from which the structured constructs have been removed). Called ev(G) |\n",
        "| ESSENTIAL_DENSITY                | (ESSCOM-1) / (v(G)-1)                                        |\n",
        "| LOC_EXECUTABLE                   | Lines of executable code                                     |\n",
        "| PARAMETER_COUNT                  | Number of parameters                                         |\n",
        "| GLOBAL_DATA_COMPLEXITY           | Complexity of the global data reduced flowgraph (count of paths through global data) |\n",
        "| GLOBAL_DATA_DENSITY              | GLOBAL_DATA_COMPLEXITY divided by v(G).                      |\n",
        "| HALSTEAD_CONTENT                 | Equal to L * V (L level, V volume). It represents the complexity regardless of the language used |\n",
        "| HALSTEAD_DIFFICULTY              | Error proneness of the program, computed as D=(UOP/2)*(OD/UOD) |\n",
        "| HALSTEAD_EFFORT                  | E = D * V (D difficulty, V volume). It represents the mental effort required to develop or maintain a class |\n",
        "| HALSTEAD_ERROR_EST               | Estimated Halstead error                                     |\n",
        "| HALSTEAD_LENGTH                  | Total of all the lengths in the classes                      |\n",
        "| HALSTEAD_LEVEL                   | L = 1 / D                                                    |\n",
        "| HALSTEAD_PROG_TIME               | Time (in seconds) to implement a program: T = E / 18 (E Halstead effort). The number 18 comes from empirical experiments |\n",
        "| HALSTEAD_VOLUME                  | Total of all the volumes in the methods (the volume V is the information content of a program, measured in mathematical bits: V=length(program)*log2(UOD+UOP)). The length(program) = OP+OD. |\n",
        "| MAINTENANCE_SEVERITY             | ev(G) / v(G) = Essential complexity divided by Cyclomatic complexity |\n",
        "| MODIFIED_CONDITION_COUNT         | Count for MC/DC (Modified Condition/Decision Coverage)       |\n",
        "| MULTIPLE_CONDITION_COUNT         | Count for MCC (Multiple Condition Coverage)                  |\n",
        "| NODE_COUNT                       | Number of nodes in the control-flow graph                    |\n",
        "| NORMALIZED_CYCLOMATIC_COMPLEXITY | Normalized McCabe's cyclomatic complexity                    |\n",
        "| NUM_OPERANDS                     | Number of operands (OD)                                      |\n",
        "| NUM_OPERATORS                    | Number of operators (OP)                                     |\n",
        "| NUM_UNIQUE_OPERANDS              | Number of unique operands (UOD)                              |\n",
        "| NUM_UNIQUE_OPERATORS             | Number of unique operators (UOP)                             |\n",
        "| NUMBER_OF_LINES                  | Number of lines                                              |\n",
        "| PATHOLOGICAL_COMPLEXITY          | Measures the degree to which a module contains extremely unstructured constructs. Also called pv(G) |\n",
        "| PERCENT_COMMENTS                 | Percentage of comments in the total lines of code            |\n",
        "| LOC_TOTAL                        | Total lines of code                                          |\n",
        "| Defective                        | Y if the class is defective, N if not                        |\n",
        "\n",
        "\n",
        "| Metric                           | Description                                                  |\n",
        "| -------------------------------- | ------------------------------------------------------------ |\n",
        "| LOC_BLANK                        | Number of blank lines of code                                |\n",
        "| BRANCH_COUNT                     | Number of logical branches                                   |\n",
        "| CALL_PAIRS                       | Executable calls between modules                             |\n",
        "| LOC_CODE_AND_COMMENT             | Lines of code + lines of comment                             |\n",
        "| LOC_COMMENTS                     | Lines of comment                                             |\n",
        "| CONDITION_COUNT                  | Number of conditions                                         |\n",
        "| CYCLOMATIC_COMPLEXITY            | McCabe's cyclomatic complexity (maximum number of linearly independent paths through a program's source code, computed from the control-flow graph). It's the number of conditional branches in the control-flow graph. M = E - N + 2P (E number of edges, N number of nodes, P number of connected components). Also called v(G). |\n",
        "| CYCLOMATIC_DENSITY               | Cyclomatic complexity divided by the size of the system (in source statements) |\n",
        "| DECISION_COUNT                   | Number of decisions                                          |\n",
        "| DECISION_DENSITY                 | Number of decisions divided by the size of the system        |\n",
        "| DESIGN_COMPLEXITY                | Number of paths which call something                         |\n",
        "| DESIGN_DENSITY                   | Design complexity divided by cyclomatic complexity (total paths) |\n",
        "| EDGE_COUNT                       | Number of edges of the control-flow graph                    |\n",
        "| ESSENTIAL_COMPLEXITY             | ESSCOM = (NONREDUC+1) + (ENTRYPT-1) + (TERMPT-1) Essential complexity is the sum of nonreducible nodes plus one, plus one for each entry point after the first, plus one for each termination point after the first. It's basically the complexity of the reduced flowgraph (from which the structured constructs have been removed). Called ev(G) |\n",
        "| ESSENTIAL_DENSITY                | (ESSCOM-1) / (v(G)-1)                                        |\n",
        "| LOC_EXECUTABLE                   | Lines of executable code                                     |\n",
        "| PARAMETER_COUNT                  | Number of parameters                                         |\n",
        "| HALSTEAD_CONTENT                 | Equal to L * V (L level, V volume). It represents the complexity regardless of the language used |\n",
        "| HALSTEAD_DIFFICULTY              | Error proneness of the program, computed as D=(UOP/2)*(OD/UOD) |\n",
        "| HALSTEAD_EFFORT                  | E = D * V (D difficulty, V volume). It represents the mental effort required to develop or maintain a class |\n",
        "| HALSTEAD_ERROR_EST               | Estimated Halstead error                                     |\n",
        "| HALSTEAD_LENGTH                  | Total of all the lengths in the classes                      |\n",
        "| HALSTEAD_LEVEL                   | L = 1 / D                                                    |\n",
        "| HALSTEAD_PROG_TIME               | Time (in seconds) to implement a program: T = E / 18 (E Halstead effort). The number 18 comes from empirical experiments |\n",
        "| HALSTEAD_VOLUME                  | Total of all the volumes in the methods (the volume V is the information content of a program, measured in mathematical bits: V=length(program)*log2(UOD+UOP)). The length(program) = OP+OD. |\n",
        "| MAINTENANCE_SEVERITY             | ev(G) / v(G) = Essential complexity divided by Cyclomatic complexity |\n",
        "| MODIFIED_CONDITION_COUNT         | Count for MC/DC (Modified Condition/Decision Coverage)       |\n",
        "| MULTIPLE_CONDITION_COUNT         | Count for MCC (Multiple Condition Coverage)                  |\n",
        "| NODE_COUNT                       | Number of nodes in the control-flow graph                    |\n",
        "| NORMALIZED_CYCLOMATIC_COMPLEXITY | Normalized McCabe's cyclomatic complexity                    |\n",
        "| NUM_OPERANDS                     | Number of operands (OD)                                      |\n",
        "| NUM_OPERATORS                    | Number of operators (OP)                                     |\n",
        "| NUM_UNIQUE_OPERANDS              | Number of unique operands (UOD)                              |\n",
        "| NUM_UNIQUE_OPERATORS             | Number of unique operators (UOP)                             |\n",
        "| NUMBER_OF_LINES                  | Number of lines                                              |\n",
        "| PERCENT_COMMENTS                 | Percentage of comments in the total lines of code            |\n",
        "| LOC_TOTAL                        | Total lines of code                                          |\n",
        "| Defective                        | Y if the class is defective, N if not                        |\n",
        "\n",
        "\n",
        "| Metric    | Description                    |\n",
        "| --------- | ------------------------------ |\n",
        "| ID        | Class ID                       |\n",
        "| Name      | Class name                     |\n",
        "| LongName  | Extended class name            |\n",
        "| Parent    | Parent ID                      |\n",
        "| Component | Component ID                   |\n",
        "| Path      | Directory path                 |\n",
        "| Line      | Starting line                  |\n",
        "| Column    | Starting column                |\n",
        "| EndLine   | Ending line                    |\n",
        "| EndColumn | Ending column                  |\n",
        "| CC        | Cyclomatic complexity          |\n",
        "| CCL       | Not available                               |\n",
        "| CCO       | Not available                               |\n",
        "| CI        | Not available                               |\n",
        "| CLC       | Not available                               |\n",
        "| CLLC      | Not available                               |\n",
        "| LDC       | Not available                               |\n",
        "| LLDC      | Not available                               |\n",
        "| LCOM5     | Lack of cohesion methods (CK)  |\n",
        "| NL        | Not available                               |\n",
        "| NLE       | Not available                               |\n",
        "| WMC       | Weighted method count (CK)     |\n",
        "| CBO       | Coupling between objects (CK)  |\n",
        "| CBOI      | Not available                               |\n",
        "| NII       | Not available                               |\n",
        "| NOI       | Number of interfaces           |\n",
        "| RFC       | Response for a class (CK)      |\n",
        "| AD        | Anonymous declaration          |\n",
        "| CD        | Class declarations             |\n",
        "| CLOC      | Comment lines of code          |\n",
        "| DLOC      | Not available                               |\n",
        "| PDA       | Not available                               |\n",
        "| PUA       | Not available                               |\n",
        "| TCD       | Not available                               |\n",
        "| TCLOC     | Total comment lines of code    |\n",
        "| DIT       | Depth of inheritance tree (CK) |\n",
        "| NOA       | Number of attributes           |\n",
        "| NOC       | Number of children (CK)        |\n",
        "| NOD       | Number of operands                              |\n",
        "| NOP       | Number of operators                               |\n",
        "| LLOC      | Logical lines of code                               |\n",
        "| LOC       | Lines of code                  |\n",
        "| NA.       | Not available                               |\n",
        "| NG        | Not available                               |\n",
        "| NLA       | Not available                               |\n",
        "| NLG       | Not available                               |\n",
        "| NLM       | Not available                               |\n",
        "| NLPA      | Not available                               |\n",
        "| NLPM      | Not available                               |\n",
        "| NLS       | Not available                               |\n",
        "| NM        | Number of methods                               |\n",
        "| NOS       | Not available                               |\n",
        "| NPA       | Number of public attributes                               |\n",
        "| NPM       | Number of public methods                              |\n",
        "| NS        | Not available                               |\n",
        "| TLLOC     | Total logical lines of code                               |\n",
        "| TLOC      | Total lines of code            |\n",
        "| TNA       | Not available                               |\n",
        "| TNG       | Not available                               |\n",
        "| TNLA      | Not available                               |\n",
        "| TNLG      | Not available                               |\n",
        "| TNLM      | Not available                               |\n",
        "| TNLPA     | Not available                               |\n",
        "| TNLPM     | Not available                               |\n",
        "| TNLS      | Not available                               |\n",
        "| TNM       | Not available                               |\n",
        "| TNOS      | Not available                               |\n",
        "| TNPA      | Not available                               |\n",
        "| TNPM      | Not available                               |\n",
        "| TNS       | Not available                               |\n",
        "\n",
        "| Warnings and rule violations      | Description                                           |\n",
        "| --------------------------------- | ----------------------------------------------------- |\n",
        "| WarningBlocker                    | Number of blocker warnings                            |\n",
        "| WarningCritical                   | Number of critical warnings                           |\n",
        "| WarningInfo                       | Number of warning informations                        |\n",
        "| WarningMajor                      | Number of major warnings                              |\n",
        "| WarningMinor                      | Number of minor warnings                              |\n",
        "| Android.Rules                     | Number of android rule violations                     |\n",
        "| Basic.Rules                       | Number of basic rule violations                       |\n",
        "| Brace.Rules                       | Number of brace rule violations                       |\n",
        "| Clone.Implementation.Rules        | Number of clone implementation rule violations        |\n",
        "| Clone.Metric.Rules                | Number of clone metric rule violations                |\n",
        "| Code.Size.Rules                   | Number of code size rule violations                   |\n",
        "| Cohesion.Metric.Rules             | Number of cohesion metric rule violations             |\n",
        "| Comment.Rules                     | Number of comment rule violations                     |\n",
        "| Complexity.Metric.Rules           | Number of complexity metric rule violations           |\n",
        "| Controversial.Rules               | Number of controversial rule violations               |\n",
        "| Coupling.Metric.Rules             | Number of coupling metric rule violations             |\n",
        "| Coupling.Rules                    | Number of coupling rule violations                    |\n",
        "| Design.Rules                      | Number of design rule violations                      |\n",
        "| Dcoumentation.Metric.Rules        | Number of documentation metric rule violations        |\n",
        "| Empty.Code.Rules                  | Number of empty code rule violations                  |\n",
        "| Finalizer.Rules                   | Number of finalizer rule violations                   |\n",
        "| Import.Statement.Rules            | Number of import statement rule violations            |\n",
        "| Inheritance.Metric.Rules          | Number of inheritance metric rule violations          |\n",
        "| J2EE.Rules                        | Number of J2EE rule violations                        |\n",
        "| JUnit.Rules                       | Number of JUnit rule violations                       |\n",
        "| Jakarta.Commons.Logging.Rules     | Number of Jakarta commons logging rule violations     |\n",
        "| Java.Logging.Rules                | Number of Java logging rule violations                |\n",
        "| JavaBean.Rules                    | Number of JavaBean rule violations                    |\n",
        "| MigratingToJUnit4.Rules           | Number of migratingToJUnit4 rule violations           |\n",
        "| Migration.Rules                   | Number of migration rule violations                   |\n",
        "| Migration13.Rules                 | Number of migration13 rule violations                 |\n",
        "| Migration14.Rules                 | Number of migration14 rule violations                 |\n",
        "| Migration15.Rules                 | Number of migration15 rule violations                 |\n",
        "| Naming.Rules                      | Number of naming rule violations                      |\n",
        "| Optimization.Rules                | Number of optimization rule violations                |\n",
        "| Security.Code.Guideline.Rules     | Number of security code guideline rule violations     |\n",
        "| Size.Metric.Rules                 | Number of size metric rule violations                 |\n",
        "| Strict.Exception.Rules            | Number of strict exception rule violations            |\n",
        "| String.and.StringBuffer.Rules     | Number of string and string buffer rule violations    |\n",
        "| Type.Resolution.Rules             | Number of type resolution rule violations             |\n",
        "| Unnecessary.and.Unused.Code.Rules | Number of unnecessary and unused code rule violations |\n",
        "| Vulnerability.Rules               | Number of vulnerability rule violations               |\n",
        "| Number.of.bugs                    | Number of bugs found                                  |\n",
        "\n",
        "\n",
        "| Metric                           | Description                                                  |\n",
        "| -------------------------------- | ------------------------------------------------------------ |\n",
        "| ID                               | Class ID                                                     |\n",
        "| Name                             | Class name                                                   |\n",
        "| LongName                         | Extended class name                                          |\n",
        "| Parent                           | Parent ID                                                    |\n",
        "| McCC                             | McCabe's Cyclomatic Complexity                               |\n",
        "| CLOC                             | Comment lines of code                                        |\n",
        "| LLOC                             | Logical lines of code                                                             |\n",
        "| Number.of.commiters              | Number of people who commited a change                       |\n",
        "| Number.of.developer.commits      | Number of total commits made by all developers for that file |\n",
        "| Number.of.previous.modifications | Number of previous modifications of the file                 |\n",
        "| Number.of.previous.fixes         | Number of previous fixes                                     |\n",
        "| Number.of.bugs                   | Number of bugs found                                         |\n",
        "\n",
        "\n",
        "| Metric           | Description                            |\n",
        "| ---------------- | -------------------------------------- |\n",
        "| QualifiedName    | Complete name of the class             |\n",
        "| Name             | Name of the class                      |\n",
        "| Complexity       | Page 19 codemr-intelllij-userguide.pdf |\n",
        "| Coupling         | Page 19 codemr-intelllij-userguide.pdf |\n",
        "| Size             | Page 19 codemr-intelllij-userguide.pdf |\n",
        "| Lack.of.Cohesion | Page 19 codemr-intelllij-userguide.pdf |\n",
        "| CBO              | Coupling between objects (CK)          |\n",
        "| RFC              | Response for a class (CK)              |\n",
        "| SRFC             | Simple response for a class            |\n",
        "| DIT              | Depth of inheritance tree (CK)         |\n",
        "| NOC              | Number of children (CK)                |\n",
        "| WMC              | Weighted method count (CK)             |\n",
        "| LOC              | Class lines of code                    |\n",
        "| CMLOC            | Class-methods lines of code            |\n",
        "| NOF              | Number of fields                       |\n",
        "| NOSF             | Number of static fields                |\n",
        "| NOM              | Number of methods                      |\n",
        "| NOSM             | Number of static methods               |\n",
        "| NORM             | Number of overridden methods           |\n",
        "| LCOM             | Lack of cohesion methods (CK)          |\n",
        "| LCAM             | Lack of cohesion among methods         |\n",
        "| LTCC             | Lack of tight class cohesion           |\n",
        "| ATFD             | Access to foreign data                 |\n",
        "\n",
        "\n",
        "| Metric           | Description                            |\n",
        "| ---------------- | -------------------------------------- |\n",
        "| QualifiedName    | Complete name of the class             |\n",
        "| Name             | Name of the class                      |\n",
        "| Complexity       | Page 19 codemr-intelllij-userguide.pdf |\n",
        "| Coupling         | Page 19 codemr-intelllij-userguide.pdf |\n",
        "| Size             | Page 19 codemr-intelllij-userguide.pdf |\n",
        "| Lack.of.Cohesion | Page 19 codemr-intelllij-userguide.pdf |\n",
        "| Coverage         | Coverage (for packages)                |\n",
        "| #CI              | Number of classes and interfaces       |\n",
        "| #C               | Number of classes                      |\n",
        "| #I               | Number of interfaces                   |\n",
        "| LOC.1            | Package lines of code                  |\n",
        "| AC               | Afferent coupling (equal to fanIn)     |\n",
        "| EC               | Efferent coupling (equal to fanOut)    |\n",
        "| Abs              | Abstractions                           |\n",
        "| Ins              | Instability                            |\n",
        "| ND               | Normalized distance                    |\n",
        "\n",
        "\n",
        "| Metric           | Description                            |\n",
        "| ---------------- | -------------------------------------- |\n",
        "| QualifiedName    | Complete name of the class             |\n",
        "| Name             | Name of the class                      |\n",
        "| Complexity       | Page 19 codemr-intelllij-userguide.pdf |\n",
        "| Coupling         | Page 19 codemr-intelllij-userguide.pdf |\n",
        "| Size             | Page 19 codemr-intelllij-userguide.pdf |\n",
        "| Lack.of.Cohesion | Page 19 codemr-intelllij-userguide.pdf |\n",
        "| WMC.1            | Weighted method count (for methods)    |\n",
        "| Coverage.1       | Coverage (for methods)                 |\n",
        "| MCC              | McCabe's Cyclomatic Complexity         |\n",
        "| NBD              | Nested Block Depth                     |\n",
        "| LOC.2            | Method lines of code                   |\n",
        "| #Pa              | Number of parameters                   |\n",
        "| #MC              | Number of methods called               |\n",
        "| #AF              | Number of accessed fields              |\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "prosjekt.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}